{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Neural Network\n",
    "\n",
    "This notebook contains tests of the CNN architecture. Results will later be copied to the main Jupyter Notebook in the root folder of the Project 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 90000 files belonging to 10 classes.\n",
      "Using 72000 files for training.\n",
      "Using 18000 files for validation.\n",
      "Classes: ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\"\n",
    "\n",
    "data_path = os.path.abspath('../data/cinic-10_image_classification_challenge-dataset/train')\n",
    "\n",
    "seed_value = 2024\n",
    "\n",
    "train_ds, test_ds = keras.preprocessing.image_dataset_from_directory(\n",
    "    data_path,\n",
    "    validation_split=0.2,\n",
    "    subset=\"both\",\n",
    "    seed=seed_value,\n",
    "    image_size=(32, 32),\n",
    "    batch_size=16,\n",
    "    shuffle=False # False to visualize augmentation\n",
    ")\n",
    "\n",
    "class_names = train_ds.class_names\n",
    "print(f'Classes: {class_names}')\n",
    "input_shape = (32, 32, 3)\n",
    "n_classes = len(class_names)\n",
    "\n",
    "def plot_accuracy_and_loss(history_df, name, idx):\n",
    "    # Plot and save accuraccy\n",
    "    plt.plot(history_df['accuracy'])\n",
    "    plt.plot(history_df['val_accuracy'])\n",
    "    plt.title(f'{name}: accuracy')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'test'], loc='upper left')\n",
    "    path = f'train_history/{name}/{idx}_accuracy.png'\n",
    "    plt.savefig(path)\n",
    "    print(f'Accuracy plot is saved to: {path}')\n",
    "    plt.close()\n",
    "    # Plot and save loss\n",
    "    plt.figure()\n",
    "    plt.plot(history_df['loss'])\n",
    "    plt.plot(history_df['val_loss'])\n",
    "    plt.title(f'{name}: loss')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'test'], loc='upper right')\n",
    "    path = f'train_history/{name}/{idx}_loss.png'\n",
    "    plt.savefig(path)\n",
    "    print(f'Loss plot is saved to: {path}')\n",
    "    plt.close()\n",
    "\n",
    "def plot_confusion_matrix(name, idx):\n",
    "    model = keras.models.load_model('train_history/'+name+'/'+idx+'.keras')\n",
    "    images, labels = tuple(zip(*test_ds.unbatch()))\n",
    "    X_test = np.array(images)\n",
    "    y_test = np.array(labels)\n",
    "    y_pred = np.argmax(model.predict(X_test), axis=-1)\n",
    "\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(f'Accuracy: {accuracy * 100:.2f}%')\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=range(0, 10), yticklabels=range(0, 10))\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "    plt.title(f'{name} Confusion Matrix. Accuracy: {accuracy * 100:.2f}%')\n",
    "    path = f'train_history/{name}/{idx}_confusion_matrix.png'\n",
    "    plt.savefig(path)\n",
    "    print(f'Confusion matrix is saved to: {path}')\n",
    "    plt.close()\n",
    "    return accuracy\n",
    "\n",
    "def plot_accuracy_boxplot(accuracy, name): \n",
    "    plt.figure()\n",
    "    plt.boxplot(accuracy)\n",
    "    plt.xticks([1], [name])\n",
    "    plt.title(f'{name}: Accuracy boxplot')\n",
    "    path = f'train_history/{name}/boxplot.png'\n",
    "    plt.savefig(path)\n",
    "    print(f'Accuracy boxplot is saved to: {path}')\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test 1: Single convolutional layer\n",
    "Conv2D - MaxPooling2D - (Flatten) Dense (1024) - Dense (10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempt #1\n",
      "Epoch 1/10\n",
      "4500/4500 [==============================] - 73s 16ms/step - loss: 6.9584 - accuracy: 0.3302 - val_loss: 1.6841 - val_accuracy: 0.4035\n",
      "Epoch 2/10\n",
      "4500/4500 [==============================] - 73s 16ms/step - loss: 1.4700 - accuracy: 0.4743 - val_loss: 1.5687 - val_accuracy: 0.4588\n",
      "Epoch 3/10\n",
      "4500/4500 [==============================] - 72s 16ms/step - loss: 1.0609 - accuracy: 0.6315 - val_loss: 1.7221 - val_accuracy: 0.4654\n",
      "Epoch 4/10\n",
      "4500/4500 [==============================] - 70s 16ms/step - loss: 0.6399 - accuracy: 0.7858 - val_loss: 2.1110 - val_accuracy: 0.4599\n",
      "Epoch 5/10\n",
      "4500/4500 [==============================] - 70s 16ms/step - loss: 0.3356 - accuracy: 0.8956 - val_loss: 2.5846 - val_accuracy: 0.4593\n",
      "Epoch 6/10\n",
      "4500/4500 [==============================] - 69s 15ms/step - loss: 0.1860 - accuracy: 0.9459 - val_loss: 2.9754 - val_accuracy: 0.4588\n",
      "Epoch 7/10\n",
      "4500/4500 [==============================] - 70s 16ms/step - loss: 0.1157 - accuracy: 0.9682 - val_loss: 3.2841 - val_accuracy: 0.4568\n",
      "Epoch 8/10\n",
      "4500/4500 [==============================] - 71s 16ms/step - loss: 0.0856 - accuracy: 0.9772 - val_loss: 3.4657 - val_accuracy: 0.4596\n",
      "Epoch 9/10\n",
      "4500/4500 [==============================] - 69s 15ms/step - loss: 0.0658 - accuracy: 0.9822 - val_loss: 3.6487 - val_accuracy: 0.4668\n",
      "Epoch 10/10\n",
      "4500/4500 [==============================] - 70s 16ms/step - loss: 0.0526 - accuracy: 0.9864 - val_loss: 3.8323 - val_accuracy: 0.4714\n",
      "Accuracy plot is saved to: train_history/cnn1/0_accuracy.png\n",
      "Loss plot is saved to: train_history/cnn1/0_loss.png\n",
      "563/563 [==============================] - 2s 3ms/step\n",
      "Accuracy: 47.14%\n",
      "Confusion matrix is saved to: train_history/cnn1/0_confusion_matrix.png\n",
      "Attempt accuracy: 47.14%\n",
      "Attempt #2\n",
      "Epoch 1/10\n",
      "4500/4500 [==============================] - 73s 16ms/step - loss: 4.1736 - accuracy: 0.3301 - val_loss: 1.6303 - val_accuracy: 0.4093\n",
      "Epoch 2/10\n",
      "4500/4500 [==============================] - 72s 16ms/step - loss: 1.4697 - accuracy: 0.4709 - val_loss: 1.5949 - val_accuracy: 0.4452\n",
      "Epoch 3/10\n",
      "4500/4500 [==============================] - 72s 16ms/step - loss: 1.0605 - accuracy: 0.6300 - val_loss: 1.6925 - val_accuracy: 0.4653\n",
      "Epoch 4/10\n",
      "4500/4500 [==============================] - 70s 16ms/step - loss: 0.6705 - accuracy: 0.7748 - val_loss: 2.0118 - val_accuracy: 0.4617\n",
      "Epoch 5/10\n",
      "4500/4500 [==============================] - 70s 15ms/step - loss: 0.3793 - accuracy: 0.8786 - val_loss: 2.5266 - val_accuracy: 0.4629\n",
      "Epoch 6/10\n",
      "4500/4500 [==============================] - 70s 16ms/step - loss: 0.2110 - accuracy: 0.9362 - val_loss: 2.9835 - val_accuracy: 0.4611\n",
      "Epoch 7/10\n",
      "4500/4500 [==============================] - 70s 15ms/step - loss: 0.1321 - accuracy: 0.9624 - val_loss: 3.2124 - val_accuracy: 0.4619\n",
      "Epoch 8/10\n",
      "4500/4500 [==============================] - 70s 16ms/step - loss: 0.0926 - accuracy: 0.9753 - val_loss: 3.3706 - val_accuracy: 0.4633\n",
      "Epoch 9/10\n",
      "4500/4500 [==============================] - 70s 16ms/step - loss: 0.0699 - accuracy: 0.9812 - val_loss: 3.6751 - val_accuracy: 0.4673\n",
      "Epoch 10/10\n",
      "4500/4500 [==============================] - 71s 16ms/step - loss: 0.0564 - accuracy: 0.9852 - val_loss: 3.7697 - val_accuracy: 0.4629\n",
      "Accuracy plot is saved to: train_history/cnn1/1_accuracy.png\n",
      "Loss plot is saved to: train_history/cnn1/1_loss.png\n",
      "563/563 [==============================] - 2s 3ms/step\n",
      "Accuracy: 46.29%\n",
      "Confusion matrix is saved to: train_history/cnn1/1_confusion_matrix.png\n",
      "Attempt accuracy: 46.29%\n",
      "Attempt #3\n",
      "Epoch 1/10\n",
      "4500/4500 [==============================] - 72s 16ms/step - loss: 4.4797 - accuracy: 0.3251 - val_loss: 1.6662 - val_accuracy: 0.4014\n",
      "Epoch 2/10\n",
      "4500/4500 [==============================] - 71s 16ms/step - loss: 1.4783 - accuracy: 0.4658 - val_loss: 1.6108 - val_accuracy: 0.4413\n",
      "Epoch 3/10\n",
      "4500/4500 [==============================] - 70s 15ms/step - loss: 1.1037 - accuracy: 0.6116 - val_loss: 1.7270 - val_accuracy: 0.4513\n",
      "Epoch 4/10\n",
      "4500/4500 [==============================] - 70s 15ms/step - loss: 0.7247 - accuracy: 0.7543 - val_loss: 2.0900 - val_accuracy: 0.4410\n",
      "Epoch 5/10\n",
      "4500/4500 [==============================] - 71s 16ms/step - loss: 0.4293 - accuracy: 0.8612 - val_loss: 2.4243 - val_accuracy: 0.4531\n",
      "Epoch 6/10\n",
      "4500/4500 [==============================] - 71s 16ms/step - loss: 0.2560 - accuracy: 0.9226 - val_loss: 2.8812 - val_accuracy: 0.4437\n",
      "Epoch 7/10\n",
      "4500/4500 [==============================] - 71s 16ms/step - loss: 0.1631 - accuracy: 0.9536 - val_loss: 3.1801 - val_accuracy: 0.4479\n",
      "Epoch 8/10\n",
      "4500/4500 [==============================] - 72s 16ms/step - loss: 0.1138 - accuracy: 0.9684 - val_loss: 3.4846 - val_accuracy: 0.4493\n",
      "Epoch 9/10\n",
      "4500/4500 [==============================] - 72s 16ms/step - loss: 0.0862 - accuracy: 0.9764 - val_loss: 3.6416 - val_accuracy: 0.4491\n",
      "Epoch 10/10\n",
      "4500/4500 [==============================] - 71s 16ms/step - loss: 0.0683 - accuracy: 0.9811 - val_loss: 3.8612 - val_accuracy: 0.4502\n",
      "Accuracy plot is saved to: train_history/cnn1/2_accuracy.png\n",
      "Loss plot is saved to: train_history/cnn1/2_loss.png\n",
      "563/563 [==============================] - 2s 3ms/step\n",
      "Accuracy: 45.02%\n",
      "Confusion matrix is saved to: train_history/cnn1/2_confusion_matrix.png\n",
      "Attempt accuracy: 45.02%\n",
      "Attempt #4\n",
      "Epoch 1/10\n",
      "4500/4500 [==============================] - 72s 16ms/step - loss: 4.4810 - accuracy: 0.3397 - val_loss: 1.6305 - val_accuracy: 0.4128\n",
      "Epoch 2/10\n",
      "4500/4500 [==============================] - 72s 16ms/step - loss: 1.4605 - accuracy: 0.4776 - val_loss: 1.5343 - val_accuracy: 0.4601\n",
      "Epoch 3/10\n",
      "4500/4500 [==============================] - 72s 16ms/step - loss: 1.1496 - accuracy: 0.5935 - val_loss: 1.6557 - val_accuracy: 0.4645\n",
      "Epoch 4/10\n",
      "4500/4500 [==============================] - 71s 16ms/step - loss: 0.8342 - accuracy: 0.7125 - val_loss: 1.9191 - val_accuracy: 0.4673\n",
      "Epoch 5/10\n",
      "4500/4500 [==============================] - 72s 16ms/step - loss: 0.5504 - accuracy: 0.8155 - val_loss: 2.3260 - val_accuracy: 0.4648\n",
      "Epoch 6/10\n",
      "4500/4500 [==============================] - 72s 16ms/step - loss: 0.3478 - accuracy: 0.8864 - val_loss: 2.8072 - val_accuracy: 0.4567\n",
      "Epoch 7/10\n",
      "4500/4500 [==============================] - 72s 16ms/step - loss: 0.2253 - accuracy: 0.9296 - val_loss: 3.0566 - val_accuracy: 0.4493\n",
      "Epoch 8/10\n",
      "4500/4500 [==============================] - 71s 16ms/step - loss: 0.1655 - accuracy: 0.9495 - val_loss: 3.2675 - val_accuracy: 0.4675\n",
      "Epoch 9/10\n",
      "4500/4500 [==============================] - 71s 16ms/step - loss: 0.1173 - accuracy: 0.9655 - val_loss: 3.5044 - val_accuracy: 0.4691\n",
      "Epoch 10/10\n",
      "4500/4500 [==============================] - 71s 16ms/step - loss: 0.0934 - accuracy: 0.9736 - val_loss: 3.6358 - val_accuracy: 0.4695\n",
      "Accuracy plot is saved to: train_history/cnn1/3_accuracy.png\n",
      "Loss plot is saved to: train_history/cnn1/3_loss.png\n",
      "563/563 [==============================] - 2s 3ms/step\n",
      "Accuracy: 46.95%\n",
      "Confusion matrix is saved to: train_history/cnn1/3_confusion_matrix.png\n",
      "Attempt accuracy: 46.95%\n",
      "Attempt #5\n",
      "Epoch 1/10\n",
      "4500/4500 [==============================] - 96s 21ms/step - loss: 4.8404 - accuracy: 0.3319 - val_loss: 1.6269 - val_accuracy: 0.4151\n",
      "Epoch 2/10\n",
      "4500/4500 [==============================] - 76s 17ms/step - loss: 1.4656 - accuracy: 0.4742 - val_loss: 1.5411 - val_accuracy: 0.4625\n",
      "Epoch 3/10\n",
      "4500/4500 [==============================] - 72s 16ms/step - loss: 1.1050 - accuracy: 0.6109 - val_loss: 1.7173 - val_accuracy: 0.4558\n",
      "Epoch 4/10\n",
      "4500/4500 [==============================] - 72s 16ms/step - loss: 0.7452 - accuracy: 0.7456 - val_loss: 2.0282 - val_accuracy: 0.4598\n",
      "Epoch 5/10\n",
      "4500/4500 [==============================] - 72s 16ms/step - loss: 0.4504 - accuracy: 0.8538 - val_loss: 2.4776 - val_accuracy: 0.4660\n",
      "Epoch 6/10\n",
      "4500/4500 [==============================] - 72s 16ms/step - loss: 0.2632 - accuracy: 0.9197 - val_loss: 2.9630 - val_accuracy: 0.4639\n",
      "Epoch 7/10\n",
      "4500/4500 [==============================] - 72s 16ms/step - loss: 0.1630 - accuracy: 0.9522 - val_loss: 3.1792 - val_accuracy: 0.4623\n",
      "Epoch 8/10\n",
      "4500/4500 [==============================] - 72s 16ms/step - loss: 0.1099 - accuracy: 0.9692 - val_loss: 3.5072 - val_accuracy: 0.4699\n",
      "Epoch 9/10\n",
      "4500/4500 [==============================] - 72s 16ms/step - loss: 0.0863 - accuracy: 0.9765 - val_loss: 3.7840 - val_accuracy: 0.4701\n",
      "Epoch 10/10\n",
      "4500/4500 [==============================] - 72s 16ms/step - loss: 0.0671 - accuracy: 0.9826 - val_loss: 3.9167 - val_accuracy: 0.4762\n",
      "Accuracy plot is saved to: train_history/cnn1/4_accuracy.png\n",
      "Loss plot is saved to: train_history/cnn1/4_loss.png\n",
      "563/563 [==============================] - 2s 3ms/step\n",
      "Accuracy: 47.62%\n",
      "Confusion matrix is saved to: train_history/cnn1/4_confusion_matrix.png\n",
      "Attempt accuracy: 47.62%\n",
      "Attempts accuracy is saved to train_history/cnn1/accuracy.csv\n",
      "Accuracy boxplot is saved to: train_history/cnn1/boxplot.png\n"
     ]
    }
   ],
   "source": [
    "name = 'cnn1'\n",
    "n_epochs = 10\n",
    "optimizer = 'adamax'\n",
    "loss = 'sparse_categorical_crossentropy'\n",
    "n_repeat = 5\n",
    "\n",
    "keras.utils.set_random_seed(seed_value)\n",
    "\n",
    "accuracy = []\n",
    "for idx in range(n_repeat):\n",
    "  print(f'Attempt #{idx + 1}')\n",
    "  i = keras.Input(shape=input_shape)\n",
    "  x = keras.layers.Conv2D(32, (3, 3), activation='relu', padding='same')(i)\n",
    "  x = keras.layers.MaxPooling2D((2, 2))(x)\n",
    "  x = keras.layers.Flatten()(x)\n",
    "  x = keras.layers.Dense(1024, activation='relu')(x)\n",
    "  x = keras.layers.Dense(n_classes, activation='softmax')(x)\n",
    "  model = keras.Model(i, x)\n",
    "\n",
    "  model.compile(\n",
    "      optimizer=optimizer,\n",
    "      loss=loss,\n",
    "      metrics=['accuracy']\n",
    "  )\n",
    "\n",
    "  history = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=test_ds,\n",
    "    epochs=n_epochs\n",
    "  )\n",
    "  model.save(f'train_history/{name}/{idx}.keras')\n",
    "  history_df = pd.DataFrame(history.history) \n",
    "  hist_csv_file = 'train_history/' + name + '/' + str(idx) + '_history.csv'\n",
    "  with open(hist_csv_file, mode='w') as f:\n",
    "      history_df.to_csv(f)\n",
    "  plot_accuracy_and_loss(history_df, name, str(idx))\n",
    "  curr_accuracy = plot_confusion_matrix(name, str(idx))\n",
    "  accuracy.append(curr_accuracy)\n",
    "  print(f'Attempt accuracy: {curr_accuracy * 100:.2f}%')\n",
    "\n",
    "accuracy_df = pd.DataFrame(data=accuracy, columns = ['accuracy'])\n",
    "accuracy_csv_file = 'train_history/' + name + '/accuracy.csv'\n",
    "with open(accuracy_csv_file, mode='w') as f:\n",
    "    accuracy_df.to_csv(f)\n",
    "print(f'Attempts accuracy is saved to {accuracy_csv_file}')\n",
    "plot_accuracy_boxplot(accuracy, name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test 2: Single convolutional layer with normalization\n",
    "\n",
    "Conv2D - (Batch normalization) MaxPooling2D - (Flatten) Dense (1024) - Dense (10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempt #1\n",
      "Epoch 1/10\n",
      "4500/4500 [==============================] - 77s 17ms/step - loss: 1.6017 - accuracy: 0.4372 - val_loss: 1.4802 - val_accuracy: 0.4733\n",
      "Epoch 2/10\n",
      "4500/4500 [==============================] - 77s 17ms/step - loss: 1.2207 - accuracy: 0.5621 - val_loss: 1.3539 - val_accuracy: 0.5294\n",
      "Epoch 3/10\n",
      "4500/4500 [==============================] - 77s 17ms/step - loss: 0.9617 - accuracy: 0.6606 - val_loss: 1.4808 - val_accuracy: 0.5253\n",
      "Epoch 4/10\n",
      "4500/4500 [==============================] - 77s 17ms/step - loss: 0.6861 - accuracy: 0.7667 - val_loss: 1.6499 - val_accuracy: 0.5269\n",
      "Epoch 5/10\n",
      "4500/4500 [==============================] - 78s 17ms/step - loss: 0.4391 - accuracy: 0.8571 - val_loss: 2.0576 - val_accuracy: 0.4988\n",
      "Epoch 6/10\n",
      "4500/4500 [==============================] - 77s 17ms/step - loss: 0.2601 - accuracy: 0.9192 - val_loss: 2.1850 - val_accuracy: 0.5096\n",
      "Epoch 7/10\n",
      "4500/4500 [==============================] - 78s 17ms/step - loss: 0.1538 - accuracy: 0.9550 - val_loss: 2.4943 - val_accuracy: 0.5158\n",
      "Epoch 8/10\n",
      "4500/4500 [==============================] - 79s 17ms/step - loss: 0.0962 - accuracy: 0.9732 - val_loss: 2.8099 - val_accuracy: 0.5085\n",
      "Epoch 9/10\n",
      "4500/4500 [==============================] - 81s 18ms/step - loss: 0.0693 - accuracy: 0.9816 - val_loss: 3.0624 - val_accuracy: 0.5107\n",
      "Epoch 10/10\n",
      "4500/4500 [==============================] - 82s 18ms/step - loss: 0.0541 - accuracy: 0.9859 - val_loss: 3.1565 - val_accuracy: 0.5009\n",
      "Accuracy plot is saved to: train_history/cnn2/0_accuracy.png\n",
      "Loss plot is saved to: train_history/cnn2/0_loss.png\n",
      "563/563 [==============================] - 2s 4ms/step\n",
      "Accuracy: 50.09%\n",
      "Confusion matrix is saved to: train_history/cnn2/0_confusion_matrix.png\n",
      "Attempt accuracy: 50.09%\n",
      "Attempt #2\n",
      "Epoch 1/10\n",
      "4500/4500 [==============================] - 81s 18ms/step - loss: 1.5965 - accuracy: 0.4352 - val_loss: 1.4747 - val_accuracy: 0.4818\n",
      "Epoch 2/10\n",
      "4500/4500 [==============================] - 83s 18ms/step - loss: 1.2173 - accuracy: 0.5618 - val_loss: 1.3837 - val_accuracy: 0.5243\n",
      "Epoch 3/10\n",
      "4500/4500 [==============================] - 84s 19ms/step - loss: 0.9522 - accuracy: 0.6645 - val_loss: 1.5248 - val_accuracy: 0.5270\n",
      "Epoch 4/10\n",
      "4500/4500 [==============================] - 83s 18ms/step - loss: 0.6808 - accuracy: 0.7674 - val_loss: 1.6835 - val_accuracy: 0.5261\n",
      "Epoch 5/10\n",
      "4500/4500 [==============================] - 83s 19ms/step - loss: 0.4413 - accuracy: 0.8551 - val_loss: 1.9994 - val_accuracy: 0.5224\n",
      "Epoch 6/10\n",
      "4500/4500 [==============================] - 83s 19ms/step - loss: 0.2669 - accuracy: 0.9172 - val_loss: 2.4289 - val_accuracy: 0.4951\n",
      "Epoch 7/10\n",
      "4500/4500 [==============================] - 84s 19ms/step - loss: 0.1616 - accuracy: 0.9529 - val_loss: 2.5651 - val_accuracy: 0.5101\n",
      "Epoch 8/10\n",
      "4500/4500 [==============================] - 84s 19ms/step - loss: 0.1029 - accuracy: 0.9722 - val_loss: 2.7842 - val_accuracy: 0.5043\n",
      "Epoch 9/10\n",
      "4500/4500 [==============================] - 83s 18ms/step - loss: 0.0716 - accuracy: 0.9804 - val_loss: 3.0386 - val_accuracy: 0.5167\n",
      "Epoch 10/10\n",
      "4500/4500 [==============================] - 75s 17ms/step - loss: 0.0534 - accuracy: 0.9861 - val_loss: 3.0935 - val_accuracy: 0.5178\n",
      "Accuracy plot is saved to: train_history/cnn2/1_accuracy.png\n",
      "Loss plot is saved to: train_history/cnn2/1_loss.png\n",
      "563/563 [==============================] - 2s 4ms/step\n",
      "Accuracy: 51.78%\n",
      "Confusion matrix is saved to: train_history/cnn2/1_confusion_matrix.png\n",
      "Attempt accuracy: 51.78%\n",
      "Attempt #3\n",
      "Epoch 1/10\n",
      "4500/4500 [==============================] - 76s 17ms/step - loss: 1.5940 - accuracy: 0.4367 - val_loss: 1.4681 - val_accuracy: 0.4810\n",
      "Epoch 2/10\n",
      "4500/4500 [==============================] - 74s 16ms/step - loss: 1.2205 - accuracy: 0.5623 - val_loss: 1.4213 - val_accuracy: 0.5121\n",
      "Epoch 3/10\n",
      "4500/4500 [==============================] - 74s 16ms/step - loss: 0.9535 - accuracy: 0.6630 - val_loss: 1.6647 - val_accuracy: 0.4825\n",
      "Epoch 4/10\n",
      "4500/4500 [==============================] - 74s 16ms/step - loss: 0.6830 - accuracy: 0.7654 - val_loss: 1.6913 - val_accuracy: 0.5104\n",
      "Epoch 5/10\n",
      "4500/4500 [==============================] - 75s 17ms/step - loss: 0.4420 - accuracy: 0.8539 - val_loss: 1.9015 - val_accuracy: 0.5142\n",
      "Epoch 6/10\n",
      "4500/4500 [==============================] - 75s 17ms/step - loss: 0.2705 - accuracy: 0.9148 - val_loss: 2.2298 - val_accuracy: 0.5141\n",
      "Epoch 7/10\n",
      "4500/4500 [==============================] - 75s 17ms/step - loss: 0.1628 - accuracy: 0.9526 - val_loss: 2.4763 - val_accuracy: 0.5210\n",
      "Epoch 8/10\n",
      "4500/4500 [==============================] - 75s 17ms/step - loss: 0.1072 - accuracy: 0.9706 - val_loss: 2.6799 - val_accuracy: 0.5168\n",
      "Epoch 9/10\n",
      "4500/4500 [==============================] - 75s 17ms/step - loss: 0.0756 - accuracy: 0.9802 - val_loss: 2.8854 - val_accuracy: 0.5221\n",
      "Epoch 10/10\n",
      "4500/4500 [==============================] - 75s 17ms/step - loss: 0.0568 - accuracy: 0.9863 - val_loss: 3.0371 - val_accuracy: 0.5186\n",
      "Accuracy plot is saved to: train_history/cnn2/2_accuracy.png\n",
      "Loss plot is saved to: train_history/cnn2/2_loss.png\n",
      "563/563 [==============================] - 2s 4ms/step\n",
      "Accuracy: 51.86%\n",
      "Confusion matrix is saved to: train_history/cnn2/2_confusion_matrix.png\n",
      "Attempt accuracy: 51.86%\n",
      "Attempt #4\n",
      "Epoch 1/10\n",
      "4500/4500 [==============================] - 76s 17ms/step - loss: 1.5712 - accuracy: 0.4437 - val_loss: 1.4114 - val_accuracy: 0.4986\n",
      "Epoch 2/10\n",
      "4500/4500 [==============================] - 75s 17ms/step - loss: 1.2020 - accuracy: 0.5663 - val_loss: 1.3854 - val_accuracy: 0.5276\n",
      "Epoch 3/10\n",
      "4500/4500 [==============================] - 75s 17ms/step - loss: 0.9276 - accuracy: 0.6746 - val_loss: 1.5696 - val_accuracy: 0.5204\n",
      "Epoch 4/10\n",
      "4500/4500 [==============================] - 75s 17ms/step - loss: 0.6465 - accuracy: 0.7809 - val_loss: 1.7321 - val_accuracy: 0.5093\n",
      "Epoch 5/10\n",
      "4500/4500 [==============================] - 75s 17ms/step - loss: 0.4016 - accuracy: 0.8688 - val_loss: 2.0403 - val_accuracy: 0.5110\n",
      "Epoch 6/10\n",
      "4500/4500 [==============================] - 75s 17ms/step - loss: 0.2314 - accuracy: 0.9297 - val_loss: 2.3462 - val_accuracy: 0.5109\n",
      "Epoch 7/10\n",
      "4500/4500 [==============================] - 75s 17ms/step - loss: 0.1370 - accuracy: 0.9611 - val_loss: 2.6770 - val_accuracy: 0.5154\n",
      "Epoch 8/10\n",
      "4500/4500 [==============================] - 75s 17ms/step - loss: 0.0912 - accuracy: 0.9758 - val_loss: 2.8002 - val_accuracy: 0.5124\n",
      "Epoch 9/10\n",
      "4500/4500 [==============================] - 76s 17ms/step - loss: 0.0640 - accuracy: 0.9831 - val_loss: 3.0130 - val_accuracy: 0.5087\n",
      "Epoch 10/10\n",
      "4500/4500 [==============================] - 75s 17ms/step - loss: 0.0500 - accuracy: 0.9870 - val_loss: 3.0936 - val_accuracy: 0.5176\n",
      "Accuracy plot is saved to: train_history/cnn2/3_accuracy.png\n",
      "Loss plot is saved to: train_history/cnn2/3_loss.png\n",
      "563/563 [==============================] - 2s 4ms/step\n",
      "Accuracy: 51.76%\n",
      "Confusion matrix is saved to: train_history/cnn2/3_confusion_matrix.png\n",
      "Attempt accuracy: 51.76%\n",
      "Attempt #5\n",
      "Epoch 1/10\n",
      "4500/4500 [==============================] - 76s 17ms/step - loss: 1.5731 - accuracy: 0.4449 - val_loss: 1.4185 - val_accuracy: 0.4905\n",
      "Epoch 2/10\n",
      "4500/4500 [==============================] - 75s 17ms/step - loss: 1.2049 - accuracy: 0.5663 - val_loss: 1.4495 - val_accuracy: 0.5097\n",
      "Epoch 3/10\n",
      "4500/4500 [==============================] - 75s 17ms/step - loss: 0.9414 - accuracy: 0.6680 - val_loss: 1.6395 - val_accuracy: 0.4988\n",
      "Epoch 4/10\n",
      "4500/4500 [==============================] - 75s 17ms/step - loss: 0.6705 - accuracy: 0.7704 - val_loss: 1.7563 - val_accuracy: 0.5130\n",
      "Epoch 5/10\n",
      "4500/4500 [==============================] - 75s 17ms/step - loss: 0.4308 - accuracy: 0.8591 - val_loss: 1.9311 - val_accuracy: 0.5255\n",
      "Epoch 6/10\n",
      "4500/4500 [==============================] - 75s 17ms/step - loss: 0.2573 - accuracy: 0.9210 - val_loss: 2.3386 - val_accuracy: 0.5098\n",
      "Epoch 7/10\n",
      "4500/4500 [==============================] - 76s 17ms/step - loss: 0.1553 - accuracy: 0.9549 - val_loss: 2.5622 - val_accuracy: 0.5166\n",
      "Epoch 8/10\n",
      "4500/4500 [==============================] - 75s 17ms/step - loss: 0.1005 - accuracy: 0.9721 - val_loss: 2.8256 - val_accuracy: 0.5137\n",
      "Epoch 9/10\n",
      "4500/4500 [==============================] - 76s 17ms/step - loss: 0.0706 - accuracy: 0.9815 - val_loss: 3.1046 - val_accuracy: 0.5156\n",
      "Epoch 10/10\n",
      "4500/4500 [==============================] - 75s 17ms/step - loss: 0.0531 - accuracy: 0.9862 - val_loss: 3.3138 - val_accuracy: 0.5147\n",
      "Accuracy plot is saved to: train_history/cnn2/4_accuracy.png\n",
      "Loss plot is saved to: train_history/cnn2/4_loss.png\n",
      "563/563 [==============================] - 2s 4ms/step\n",
      "Accuracy: 51.47%\n",
      "Confusion matrix is saved to: train_history/cnn2/4_confusion_matrix.png\n",
      "Attempt accuracy: 51.47%\n",
      "Attempts accuracy is saved to train_history/cnn2/accuracy.csv\n",
      "Accuracy boxplot is saved to: train_history/cnn2/boxplot.png\n"
     ]
    }
   ],
   "source": [
    "name = 'cnn2'\n",
    "n_epochs = 10\n",
    "optimizer = 'adamax'\n",
    "loss = 'sparse_categorical_crossentropy'\n",
    "n_repeat = 5\n",
    "\n",
    "keras.utils.set_random_seed(seed_value)\n",
    "\n",
    "accuracy = []\n",
    "for idx in range(n_repeat):\n",
    "  print(f'Attempt #{idx + 1}')\n",
    "  i = keras.Input(shape=input_shape)\n",
    "  x = keras.layers.Conv2D(32, (3, 3), activation='relu', padding='same')(i)\n",
    "  x = keras.layers.BatchNormalization()(x)\n",
    "  x = keras.layers.MaxPooling2D((2, 2))(x)\n",
    "  x = keras.layers.Flatten()(x)\n",
    "  x = keras.layers.Dense(1024, activation='relu')(x)\n",
    "  x = keras.layers.Dense(n_classes, activation='softmax')(x)\n",
    "  model = keras.Model(i, x)\n",
    "\n",
    "  model.compile(\n",
    "      optimizer=optimizer,\n",
    "      loss=loss,\n",
    "      metrics=['accuracy']\n",
    "  )\n",
    "\n",
    "  history = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=test_ds,\n",
    "    epochs=n_epochs\n",
    "  )\n",
    "  model.save(f'train_history/{name}/{idx}.keras')\n",
    "  history_df = pd.DataFrame(history.history) \n",
    "  hist_csv_file = 'train_history/' + name + '/' + str(idx) + '_history.csv'\n",
    "  with open(hist_csv_file, mode='w') as f:\n",
    "      history_df.to_csv(f)\n",
    "  plot_accuracy_and_loss(history_df, name, str(idx))\n",
    "  curr_accuracy = plot_confusion_matrix(name, str(idx))\n",
    "  accuracy.append(curr_accuracy)\n",
    "  print(f'Attempt accuracy: {curr_accuracy * 100:.2f}%')\n",
    "\n",
    "accuracy_df = pd.DataFrame(data=accuracy, columns = ['accuracy'])\n",
    "accuracy_csv_file = 'train_history/' + name + '/accuracy.csv'\n",
    "with open(accuracy_csv_file, mode='w') as f:\n",
    "    accuracy_df.to_csv(f)\n",
    "print(f'Attempts accuracy is saved to {accuracy_csv_file}')\n",
    "plot_accuracy_boxplot(accuracy, name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test 3: Dropout layer\n",
    "\n",
    "Conv2D - (Batch normalization) MaxPooling2D - (Flatten) Dropout - Dense (1024) - Dropout - Dense (10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempt #1\n",
      "Epoch 1/10\n",
      "4500/4500 [==============================] - 78s 17ms/step - loss: 1.6980 - accuracy: 0.4041 - val_loss: 1.5727 - val_accuracy: 0.4527\n",
      "Epoch 2/10\n",
      "4500/4500 [==============================] - 78s 17ms/step - loss: 1.3610 - accuracy: 0.5068 - val_loss: 1.3844 - val_accuracy: 0.5098\n",
      "Epoch 3/10\n",
      "4500/4500 [==============================] - 78s 17ms/step - loss: 1.1993 - accuracy: 0.5704 - val_loss: 1.4137 - val_accuracy: 0.5074\n",
      "Epoch 4/10\n",
      "4500/4500 [==============================] - 78s 17ms/step - loss: 1.0499 - accuracy: 0.6264 - val_loss: 1.4221 - val_accuracy: 0.5316\n",
      "Epoch 5/10\n",
      "4500/4500 [==============================] - 78s 17ms/step - loss: 0.9061 - accuracy: 0.6795 - val_loss: 1.4359 - val_accuracy: 0.5421\n",
      "Epoch 6/10\n",
      "4500/4500 [==============================] - 78s 17ms/step - loss: 0.7634 - accuracy: 0.7314 - val_loss: 1.5106 - val_accuracy: 0.5420\n",
      "Epoch 7/10\n",
      "4500/4500 [==============================] - 78s 17ms/step - loss: 0.6420 - accuracy: 0.7774 - val_loss: 1.6631 - val_accuracy: 0.5388\n",
      "Epoch 8/10\n",
      "4500/4500 [==============================] - 78s 17ms/step - loss: 0.5369 - accuracy: 0.8132 - val_loss: 1.7282 - val_accuracy: 0.5327\n",
      "Epoch 9/10\n",
      "4500/4500 [==============================] - 78s 17ms/step - loss: 0.4499 - accuracy: 0.8463 - val_loss: 1.8956 - val_accuracy: 0.5282\n",
      "Epoch 10/10\n",
      "4500/4500 [==============================] - 78s 17ms/step - loss: 0.3773 - accuracy: 0.8724 - val_loss: 1.9070 - val_accuracy: 0.5261\n",
      "Accuracy plot is saved to: train_history/cnn3/0_accuracy.png\n",
      "Loss plot is saved to: train_history/cnn3/0_loss.png\n",
      "563/563 [==============================] - 2s 4ms/step\n",
      "Accuracy: 52.61%\n",
      "Confusion matrix is saved to: train_history/cnn3/0_confusion_matrix.png\n",
      "Attempt accuracy: 52.61%\n",
      "Attempt #2\n",
      "Epoch 1/10\n",
      "4500/4500 [==============================] - 77s 17ms/step - loss: 1.7012 - accuracy: 0.4016 - val_loss: 1.5107 - val_accuracy: 0.4658\n",
      "Epoch 2/10\n",
      "4500/4500 [==============================] - 77s 17ms/step - loss: 1.3756 - accuracy: 0.5034 - val_loss: 1.3717 - val_accuracy: 0.5189\n",
      "Epoch 3/10\n",
      "4500/4500 [==============================] - 77s 17ms/step - loss: 1.2144 - accuracy: 0.5631 - val_loss: 1.3835 - val_accuracy: 0.5282\n",
      "Epoch 4/10\n",
      "4500/4500 [==============================] - 77s 17ms/step - loss: 1.0650 - accuracy: 0.6211 - val_loss: 1.4742 - val_accuracy: 0.5203\n",
      "Epoch 5/10\n",
      "4500/4500 [==============================] - 77s 17ms/step - loss: 0.9202 - accuracy: 0.6729 - val_loss: 1.5232 - val_accuracy: 0.5193\n",
      "Epoch 6/10\n",
      "4500/4500 [==============================] - 77s 17ms/step - loss: 0.7837 - accuracy: 0.7247 - val_loss: 1.5895 - val_accuracy: 0.5341\n",
      "Epoch 7/10\n",
      "4500/4500 [==============================] - 77s 17ms/step - loss: 0.6609 - accuracy: 0.7692 - val_loss: 1.6673 - val_accuracy: 0.5339\n",
      "Epoch 8/10\n",
      "4500/4500 [==============================] - 77s 17ms/step - loss: 0.5584 - accuracy: 0.8044 - val_loss: 1.7430 - val_accuracy: 0.5392\n",
      "Epoch 9/10\n",
      "4500/4500 [==============================] - 77s 17ms/step - loss: 0.4773 - accuracy: 0.8346 - val_loss: 1.8619 - val_accuracy: 0.5357\n",
      "Epoch 10/10\n",
      "4500/4500 [==============================] - 77s 17ms/step - loss: 0.4104 - accuracy: 0.8601 - val_loss: 2.0760 - val_accuracy: 0.5284\n",
      "Accuracy plot is saved to: train_history/cnn3/1_accuracy.png\n",
      "Loss plot is saved to: train_history/cnn3/1_loss.png\n",
      "563/563 [==============================] - 2s 4ms/step\n",
      "Accuracy: 52.84%\n",
      "Confusion matrix is saved to: train_history/cnn3/1_confusion_matrix.png\n",
      "Attempt accuracy: 52.84%\n",
      "Attempt #3\n",
      "Epoch 1/10\n",
      "4500/4500 [==============================] - 72s 16ms/step - loss: 1.6940 - accuracy: 0.4065 - val_loss: 1.4733 - val_accuracy: 0.4728\n",
      "Epoch 2/10\n",
      "4500/4500 [==============================] - 72s 16ms/step - loss: 1.3603 - accuracy: 0.5111 - val_loss: 1.3721 - val_accuracy: 0.5163\n",
      "Epoch 3/10\n",
      "4500/4500 [==============================] - 72s 16ms/step - loss: 1.1915 - accuracy: 0.5721 - val_loss: 1.4297 - val_accuracy: 0.5176\n",
      "Epoch 4/10\n",
      "4500/4500 [==============================] - 71s 16ms/step - loss: 1.0335 - accuracy: 0.6335 - val_loss: 1.4299 - val_accuracy: 0.5362\n",
      "Epoch 5/10\n",
      "4500/4500 [==============================] - 72s 16ms/step - loss: 0.8824 - accuracy: 0.6903 - val_loss: 1.4538 - val_accuracy: 0.5402\n",
      "Epoch 6/10\n",
      "4500/4500 [==============================] - 72s 16ms/step - loss: 0.7379 - accuracy: 0.7423 - val_loss: 1.5270 - val_accuracy: 0.5470\n",
      "Epoch 7/10\n",
      "4500/4500 [==============================] - 72s 16ms/step - loss: 0.6244 - accuracy: 0.7843 - val_loss: 1.6117 - val_accuracy: 0.5413\n",
      "Epoch 8/10\n",
      "4500/4500 [==============================] - 72s 16ms/step - loss: 0.5280 - accuracy: 0.8194 - val_loss: 1.7653 - val_accuracy: 0.5384\n",
      "Epoch 9/10\n",
      "4500/4500 [==============================] - 73s 16ms/step - loss: 0.4426 - accuracy: 0.8493 - val_loss: 1.8254 - val_accuracy: 0.5308\n",
      "Epoch 10/10\n",
      "4500/4500 [==============================] - 73s 16ms/step - loss: 0.3807 - accuracy: 0.8711 - val_loss: 1.9633 - val_accuracy: 0.5286\n",
      "Accuracy plot is saved to: train_history/cnn3/2_accuracy.png\n",
      "Loss plot is saved to: train_history/cnn3/2_loss.png\n",
      "563/563 [==============================] - 2s 4ms/step\n",
      "Accuracy: 52.86%\n",
      "Confusion matrix is saved to: train_history/cnn3/2_confusion_matrix.png\n",
      "Attempt accuracy: 52.86%\n",
      "Attempt #4\n",
      "Epoch 1/10\n",
      "4500/4500 [==============================] - 78s 17ms/step - loss: 1.6959 - accuracy: 0.4060 - val_loss: 1.4901 - val_accuracy: 0.4684\n",
      "Epoch 2/10\n",
      "4500/4500 [==============================] - 77s 17ms/step - loss: 1.3679 - accuracy: 0.5055 - val_loss: 1.3985 - val_accuracy: 0.5045\n",
      "Epoch 3/10\n",
      "4500/4500 [==============================] - 77s 17ms/step - loss: 1.1896 - accuracy: 0.5743 - val_loss: 1.4111 - val_accuracy: 0.5209\n",
      "Epoch 4/10\n",
      "4500/4500 [==============================] - 77s 17ms/step - loss: 1.0271 - accuracy: 0.6337 - val_loss: 1.4105 - val_accuracy: 0.5319\n",
      "Epoch 5/10\n",
      "4500/4500 [==============================] - 77s 17ms/step - loss: 0.8746 - accuracy: 0.6909 - val_loss: 1.4257 - val_accuracy: 0.5479\n",
      "Epoch 6/10\n",
      "4500/4500 [==============================] - 77s 17ms/step - loss: 0.7287 - accuracy: 0.7455 - val_loss: 1.5560 - val_accuracy: 0.5441\n",
      "Epoch 7/10\n",
      "4500/4500 [==============================] - 77s 17ms/step - loss: 0.6029 - accuracy: 0.7914 - val_loss: 1.6400 - val_accuracy: 0.5357\n",
      "Epoch 8/10\n",
      "4500/4500 [==============================] - 77s 17ms/step - loss: 0.5058 - accuracy: 0.8266 - val_loss: 1.7185 - val_accuracy: 0.5333\n",
      "Epoch 9/10\n",
      "4500/4500 [==============================] - 77s 17ms/step - loss: 0.4201 - accuracy: 0.8561 - val_loss: 1.8190 - val_accuracy: 0.5273\n",
      "Epoch 10/10\n",
      "4500/4500 [==============================] - 77s 17ms/step - loss: 0.3574 - accuracy: 0.8790 - val_loss: 2.0937 - val_accuracy: 0.5342\n",
      "Accuracy plot is saved to: train_history/cnn3/3_accuracy.png\n",
      "Loss plot is saved to: train_history/cnn3/3_loss.png\n",
      "563/563 [==============================] - 2s 4ms/step\n",
      "Accuracy: 53.42%\n",
      "Confusion matrix is saved to: train_history/cnn3/3_confusion_matrix.png\n",
      "Attempt accuracy: 53.42%\n",
      "Attempt #5\n",
      "Epoch 1/10\n",
      "4500/4500 [==============================] - 78s 17ms/step - loss: 1.6667 - accuracy: 0.4132 - val_loss: 1.4088 - val_accuracy: 0.4947\n",
      "Epoch 2/10\n",
      "4500/4500 [==============================] - 78s 17ms/step - loss: 1.3359 - accuracy: 0.5168 - val_loss: 1.4331 - val_accuracy: 0.4989\n",
      "Epoch 3/10\n",
      "4500/4500 [==============================] - 78s 17ms/step - loss: 1.1755 - accuracy: 0.5793 - val_loss: 1.3806 - val_accuracy: 0.5289\n",
      "Epoch 4/10\n",
      "4500/4500 [==============================] - 78s 17ms/step - loss: 1.0142 - accuracy: 0.6399 - val_loss: 1.3747 - val_accuracy: 0.5421\n",
      "Epoch 5/10\n",
      "4500/4500 [==============================] - 77s 17ms/step - loss: 0.8615 - accuracy: 0.6967 - val_loss: 1.5093 - val_accuracy: 0.5468\n",
      "Epoch 6/10\n",
      "4500/4500 [==============================] - 77s 17ms/step - loss: 0.7173 - accuracy: 0.7481 - val_loss: 1.5737 - val_accuracy: 0.5488\n",
      "Epoch 7/10\n",
      "4500/4500 [==============================] - 77s 17ms/step - loss: 0.5959 - accuracy: 0.7943 - val_loss: 1.6467 - val_accuracy: 0.5404\n",
      "Epoch 8/10\n",
      "4500/4500 [==============================] - 76s 17ms/step - loss: 0.4949 - accuracy: 0.8306 - val_loss: 1.7467 - val_accuracy: 0.5396\n",
      "Epoch 9/10\n",
      "4500/4500 [==============================] - 76s 17ms/step - loss: 0.4124 - accuracy: 0.8589 - val_loss: 1.9510 - val_accuracy: 0.5227\n",
      "Epoch 10/10\n",
      "4500/4500 [==============================] - 76s 17ms/step - loss: 0.3490 - accuracy: 0.8823 - val_loss: 2.0216 - val_accuracy: 0.5272\n",
      "Accuracy plot is saved to: train_history/cnn3/4_accuracy.png\n",
      "Loss plot is saved to: train_history/cnn3/4_loss.png\n",
      "563/563 [==============================] - 2s 4ms/step\n",
      "Accuracy: 52.72%\n",
      "Confusion matrix is saved to: train_history/cnn3/4_confusion_matrix.png\n",
      "Attempt accuracy: 52.72%\n",
      "Attempts accuracy is saved to train_history/cnn3/accuracy.csv\n",
      "Accuracy boxplot is saved to: train_history/cnn3/boxplot.png\n"
     ]
    }
   ],
   "source": [
    "name = 'cnn3'\n",
    "n_epochs = 10\n",
    "optimizer = 'adamax'\n",
    "loss = 'sparse_categorical_crossentropy'\n",
    "n_repeat = 5\n",
    "\n",
    "keras.utils.set_random_seed(seed_value)\n",
    "\n",
    "accuracy = []\n",
    "for idx in range(n_repeat):\n",
    "  print(f'Attempt #{idx + 1}')\n",
    "  i = keras.Input(shape=input_shape)\n",
    "  x = keras.layers.Conv2D(32, (3, 3), activation='relu', padding='same')(i)\n",
    "  x = keras.layers.BatchNormalization()(x)\n",
    "  x = keras.layers.MaxPooling2D((2, 2))(x)\n",
    "  x = keras.layers.Flatten()(x)\n",
    "  x = keras.layers.Dropout(0.2)(x)\n",
    "  x = keras.layers.Dense(1024, activation='relu')(x)\n",
    "  x = keras.layers.Dropout(0.2)(x)\n",
    "  x = keras.layers.Dense(n_classes, activation='softmax')(x)\n",
    "  model = keras.Model(i, x)\n",
    "\n",
    "  model.compile(\n",
    "      optimizer=optimizer,\n",
    "      loss=loss,\n",
    "      metrics=['accuracy']\n",
    "  )\n",
    "\n",
    "  history = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=test_ds,\n",
    "    epochs=n_epochs\n",
    "  )\n",
    "  model.save(f'train_history/{name}/{idx}.keras')\n",
    "  history_df = pd.DataFrame(history.history) \n",
    "  hist_csv_file = 'train_history/' + name + '/' + str(idx) + '_history.csv'\n",
    "  with open(hist_csv_file, mode='w') as f:\n",
    "      history_df.to_csv(f)\n",
    "  plot_accuracy_and_loss(history_df, name, str(idx))\n",
    "  curr_accuracy = plot_confusion_matrix(name, str(idx))\n",
    "  accuracy.append(curr_accuracy)\n",
    "  print(f'Attempt accuracy: {curr_accuracy * 100:.2f}%')\n",
    "\n",
    "accuracy_df = pd.DataFrame(data=accuracy, columns = ['accuracy'])\n",
    "accuracy_csv_file = 'train_history/' + name + '/accuracy.csv'\n",
    "with open(accuracy_csv_file, mode='w') as f:\n",
    "    accuracy_df.to_csv(f)\n",
    "print(f'Attempts accuracy is saved to {accuracy_csv_file}')\n",
    "plot_accuracy_boxplot(accuracy, name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test 4: Multiple convolutional layers\n",
    "\n",
    "Conv2D - (Batch normalization) Conv2D - (Batch normalization) MaxPooling2D - \n",
    "\n",
    "Conv2D - (Batch normalization) Conv2D - (Batch normalization) MaxPooling2D - \n",
    "\n",
    "(Flatten) Dropout - Dense (1024) - Dropout - Dense (10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempt #1\n",
      "Epoch 1/10\n",
      "4500/4500 [==============================] - 112s 25ms/step - loss: 1.5707 - accuracy: 0.4392 - val_loss: 1.2650 - val_accuracy: 0.5459\n",
      "Epoch 2/10\n",
      "4500/4500 [==============================] - 86s 19ms/step - loss: 1.2096 - accuracy: 0.5639 - val_loss: 1.1469 - val_accuracy: 0.5898\n",
      "Epoch 3/10\n",
      "4500/4500 [==============================] - 87s 19ms/step - loss: 1.0378 - accuracy: 0.6266 - val_loss: 1.1283 - val_accuracy: 0.6103\n",
      "Epoch 4/10\n",
      "4500/4500 [==============================] - 87s 19ms/step - loss: 0.8885 - accuracy: 0.6801 - val_loss: 1.0876 - val_accuracy: 0.6339\n",
      "Epoch 5/10\n",
      "4500/4500 [==============================] - 86s 19ms/step - loss: 0.7408 - accuracy: 0.7358 - val_loss: 1.1802 - val_accuracy: 0.6255\n",
      "Epoch 6/10\n",
      "4500/4500 [==============================] - 88s 19ms/step - loss: 0.6006 - accuracy: 0.7863 - val_loss: 1.2076 - val_accuracy: 0.6260\n",
      "Epoch 7/10\n",
      "4500/4500 [==============================] - 87s 19ms/step - loss: 0.4762 - accuracy: 0.8314 - val_loss: 1.1946 - val_accuracy: 0.6448\n",
      "Epoch 8/10\n",
      "4500/4500 [==============================] - 87s 19ms/step - loss: 0.3638 - accuracy: 0.8728 - val_loss: 1.2958 - val_accuracy: 0.6444\n",
      "Epoch 9/10\n",
      "4500/4500 [==============================] - 88s 19ms/step - loss: 0.2924 - accuracy: 0.8981 - val_loss: 1.3255 - val_accuracy: 0.6408\n",
      "Epoch 10/10\n",
      "4500/4500 [==============================] - 87s 19ms/step - loss: 0.2372 - accuracy: 0.9169 - val_loss: 1.4083 - val_accuracy: 0.6513\n",
      "Accuracy plot is saved to: train_history/cnn4/0_accuracy.png\n",
      "Loss plot is saved to: train_history/cnn4/0_loss.png\n",
      "563/563 [==============================] - 4s 7ms/step\n",
      "Accuracy: 65.13%\n",
      "Confusion matrix is saved to: train_history/cnn4/0_confusion_matrix.png\n",
      "Attempt accuracy: 65.13%\n",
      "Attempt #2\n",
      "Epoch 1/10\n",
      "4500/4500 [==============================] - 88s 20ms/step - loss: 1.5654 - accuracy: 0.4431 - val_loss: 1.2305 - val_accuracy: 0.5534\n",
      "Epoch 2/10\n",
      "4500/4500 [==============================] - 88s 20ms/step - loss: 1.2041 - accuracy: 0.5660 - val_loss: 1.1142 - val_accuracy: 0.5999\n",
      "Epoch 3/10\n",
      "4500/4500 [==============================] - 87s 19ms/step - loss: 1.0281 - accuracy: 0.6297 - val_loss: 1.0804 - val_accuracy: 0.6179\n",
      "Epoch 4/10\n",
      "4500/4500 [==============================] - 87s 19ms/step - loss: 0.8774 - accuracy: 0.6845 - val_loss: 1.0775 - val_accuracy: 0.6327\n",
      "Epoch 5/10\n",
      "4500/4500 [==============================] - 88s 19ms/step - loss: 0.7355 - accuracy: 0.7369 - val_loss: 1.0502 - val_accuracy: 0.6474\n",
      "Epoch 6/10\n",
      "4500/4500 [==============================] - 88s 20ms/step - loss: 0.5930 - accuracy: 0.7906 - val_loss: 1.1299 - val_accuracy: 0.6378\n",
      "Epoch 7/10\n",
      "4500/4500 [==============================] - 88s 19ms/step - loss: 0.4667 - accuracy: 0.8349 - val_loss: 1.1813 - val_accuracy: 0.6389\n",
      "Epoch 8/10\n",
      "4500/4500 [==============================] - 88s 20ms/step - loss: 0.3653 - accuracy: 0.8730 - val_loss: 1.2114 - val_accuracy: 0.6405\n",
      "Epoch 9/10\n",
      "4500/4500 [==============================] - 88s 20ms/step - loss: 0.2887 - accuracy: 0.9001 - val_loss: 1.3143 - val_accuracy: 0.6486\n",
      "Epoch 10/10\n",
      "4500/4500 [==============================] - 88s 20ms/step - loss: 0.2338 - accuracy: 0.9192 - val_loss: 1.3302 - val_accuracy: 0.6435\n",
      "Accuracy plot is saved to: train_history/cnn4/1_accuracy.png\n",
      "Loss plot is saved to: train_history/cnn4/1_loss.png\n",
      "563/563 [==============================] - 4s 7ms/step\n",
      "Accuracy: 64.35%\n",
      "Confusion matrix is saved to: train_history/cnn4/1_confusion_matrix.png\n",
      "Attempt accuracy: 64.35%\n",
      "Attempt #3\n",
      "Epoch 1/10\n",
      "4500/4500 [==============================] - 90s 20ms/step - loss: 1.5536 - accuracy: 0.4437 - val_loss: 1.2626 - val_accuracy: 0.5442\n",
      "Epoch 2/10\n",
      "4500/4500 [==============================] - 90s 20ms/step - loss: 1.2033 - accuracy: 0.5643 - val_loss: 1.1444 - val_accuracy: 0.5879\n",
      "Epoch 3/10\n",
      "4500/4500 [==============================] - 90s 20ms/step - loss: 1.0369 - accuracy: 0.6267 - val_loss: 1.1140 - val_accuracy: 0.6071\n",
      "Epoch 4/10\n",
      "4500/4500 [==============================] - 90s 20ms/step - loss: 0.8853 - accuracy: 0.6851 - val_loss: 1.0757 - val_accuracy: 0.6281\n",
      "Epoch 5/10\n",
      "4500/4500 [==============================] - 89s 20ms/step - loss: 0.7484 - accuracy: 0.7332 - val_loss: 1.1499 - val_accuracy: 0.6229\n",
      "Epoch 6/10\n",
      "4500/4500 [==============================] - 89s 20ms/step - loss: 0.6067 - accuracy: 0.7857 - val_loss: 1.1025 - val_accuracy: 0.6467\n",
      "Epoch 7/10\n",
      "4500/4500 [==============================] - 90s 20ms/step - loss: 0.4790 - accuracy: 0.8318 - val_loss: 1.1637 - val_accuracy: 0.6436\n",
      "Epoch 8/10\n",
      "4500/4500 [==============================] - 90s 20ms/step - loss: 0.3692 - accuracy: 0.8725 - val_loss: 1.2648 - val_accuracy: 0.6445\n",
      "Epoch 9/10\n",
      "4500/4500 [==============================] - 90s 20ms/step - loss: 0.3010 - accuracy: 0.8943 - val_loss: 1.2987 - val_accuracy: 0.6430\n",
      "Epoch 10/10\n",
      "4500/4500 [==============================] - 90s 20ms/step - loss: 0.2451 - accuracy: 0.9147 - val_loss: 1.3739 - val_accuracy: 0.6425\n",
      "Accuracy plot is saved to: train_history/cnn4/2_accuracy.png\n",
      "Loss plot is saved to: train_history/cnn4/2_loss.png\n",
      "563/563 [==============================] - 4s 8ms/step\n",
      "Accuracy: 64.25%\n",
      "Confusion matrix is saved to: train_history/cnn4/2_confusion_matrix.png\n",
      "Attempt accuracy: 64.25%\n",
      "Attempt #4\n",
      "Epoch 1/10\n",
      "4500/4500 [==============================] - 88s 19ms/step - loss: 1.5870 - accuracy: 0.4352 - val_loss: 1.3312 - val_accuracy: 0.5195\n",
      "Epoch 2/10\n",
      "4500/4500 [==============================] - 87s 19ms/step - loss: 1.2162 - accuracy: 0.5603 - val_loss: 1.1331 - val_accuracy: 0.5893\n",
      "Epoch 3/10\n",
      "4500/4500 [==============================] - 87s 19ms/step - loss: 1.0428 - accuracy: 0.6253 - val_loss: 1.0583 - val_accuracy: 0.6234\n",
      "Epoch 4/10\n",
      "4500/4500 [==============================] - 87s 19ms/step - loss: 0.8915 - accuracy: 0.6815 - val_loss: 1.0437 - val_accuracy: 0.6362\n",
      "Epoch 5/10\n",
      "4500/4500 [==============================] - 87s 19ms/step - loss: 0.7492 - accuracy: 0.7311 - val_loss: 1.0649 - val_accuracy: 0.6310\n",
      "Epoch 6/10\n",
      "4500/4500 [==============================] - 87s 19ms/step - loss: 0.6065 - accuracy: 0.7839 - val_loss: 1.0931 - val_accuracy: 0.6462\n",
      "Epoch 7/10\n",
      "4500/4500 [==============================] - 87s 19ms/step - loss: 0.4748 - accuracy: 0.8322 - val_loss: 1.1428 - val_accuracy: 0.6385\n",
      "Epoch 8/10\n",
      "4500/4500 [==============================] - 87s 19ms/step - loss: 0.3679 - accuracy: 0.8712 - val_loss: 1.2196 - val_accuracy: 0.6538\n",
      "Epoch 9/10\n",
      "4500/4500 [==============================] - 87s 19ms/step - loss: 0.2967 - accuracy: 0.8970 - val_loss: 1.3007 - val_accuracy: 0.6413\n",
      "Epoch 10/10\n",
      "4500/4500 [==============================] - 86s 19ms/step - loss: 0.2395 - accuracy: 0.9183 - val_loss: 1.3184 - val_accuracy: 0.6452\n",
      "Accuracy plot is saved to: train_history/cnn4/3_accuracy.png\n",
      "Loss plot is saved to: train_history/cnn4/3_loss.png\n",
      "563/563 [==============================] - 4s 7ms/step\n",
      "Accuracy: 64.52%\n",
      "Confusion matrix is saved to: train_history/cnn4/3_confusion_matrix.png\n",
      "Attempt accuracy: 64.52%\n",
      "Attempt #5\n",
      "Epoch 1/10\n",
      "4500/4500 [==============================] - 92s 20ms/step - loss: 1.5800 - accuracy: 0.4408 - val_loss: 1.2509 - val_accuracy: 0.5427\n",
      "Epoch 2/10\n",
      "4500/4500 [==============================] - 90s 20ms/step - loss: 1.2084 - accuracy: 0.5641 - val_loss: 1.1553 - val_accuracy: 0.5887\n",
      "Epoch 3/10\n",
      "4500/4500 [==============================] - 135s 30ms/step - loss: 1.0393 - accuracy: 0.6264 - val_loss: 1.2310 - val_accuracy: 0.5870\n",
      "Epoch 4/10\n",
      "4500/4500 [==============================] - 87s 19ms/step - loss: 0.8934 - accuracy: 0.6808 - val_loss: 1.1414 - val_accuracy: 0.6234\n",
      "Epoch 5/10\n",
      "4500/4500 [==============================] - 88s 20ms/step - loss: 0.7492 - accuracy: 0.7320 - val_loss: 1.0905 - val_accuracy: 0.6428\n",
      "Epoch 6/10\n",
      "4500/4500 [==============================] - 89s 20ms/step - loss: 0.6035 - accuracy: 0.7878 - val_loss: 1.1643 - val_accuracy: 0.6349\n",
      "Epoch 7/10\n",
      "4500/4500 [==============================] - 89s 20ms/step - loss: 0.4815 - accuracy: 0.8296 - val_loss: 1.2198 - val_accuracy: 0.6259\n",
      "Epoch 8/10\n",
      "4500/4500 [==============================] - 89s 20ms/step - loss: 0.3740 - accuracy: 0.8683 - val_loss: 1.2092 - val_accuracy: 0.6444\n",
      "Epoch 9/10\n",
      "4500/4500 [==============================] - 89s 20ms/step - loss: 0.2980 - accuracy: 0.8952 - val_loss: 1.3230 - val_accuracy: 0.6491\n",
      "Epoch 10/10\n",
      "4500/4500 [==============================] - 89s 20ms/step - loss: 0.2406 - accuracy: 0.9159 - val_loss: 1.3934 - val_accuracy: 0.6398\n",
      "Accuracy plot is saved to: train_history/cnn4/4_accuracy.png\n",
      "Loss plot is saved to: train_history/cnn4/4_loss.png\n",
      "563/563 [==============================] - 4s 7ms/step\n",
      "Accuracy: 63.98%\n",
      "Confusion matrix is saved to: train_history/cnn4/4_confusion_matrix.png\n",
      "Attempt accuracy: 63.98%\n",
      "Attempts accuracy is saved to train_history/cnn4/accuracy.csv\n",
      "Accuracy boxplot is saved to: train_history/cnn4/boxplot.png\n"
     ]
    }
   ],
   "source": [
    "name = 'cnn4'\n",
    "n_epochs = 10\n",
    "optimizer = 'adamax'\n",
    "loss = 'sparse_categorical_crossentropy'\n",
    "n_repeat = 5\n",
    "\n",
    "keras.utils.set_random_seed(seed_value)\n",
    "\n",
    "accuracy = []\n",
    "for idx in range(n_repeat):\n",
    "  print(f'Attempt #{idx + 1}')\n",
    "  i = keras.Input(shape=input_shape)\n",
    "  x = keras.layers.Conv2D(32, (3, 3), activation='relu', padding='same')(i)\n",
    "  x = keras.layers.BatchNormalization()(x)\n",
    "  x = keras.layers.Conv2D(32, (3, 3), activation='relu', padding='same')(x)\n",
    "  x = keras.layers.BatchNormalization()(x)\n",
    "  x = keras.layers.MaxPooling2D((2, 2))(x)\n",
    "\n",
    "  x = keras.layers.Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
    "  x = keras.layers.BatchNormalization()(x)\n",
    "  x = keras.layers.Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
    "  x = keras.layers.BatchNormalization()(x)\n",
    "  x = keras.layers.MaxPooling2D((2, 2))(x)\n",
    "\n",
    "  x = keras.layers.Flatten()(x)\n",
    "  x = keras.layers.Dropout(0.2)(x)\n",
    "  x = keras.layers.Dense(1024, activation='relu')(x)\n",
    "  x = keras.layers.Dropout(0.2)(x)\n",
    "  x = keras.layers.Dense(n_classes, activation='softmax')(x)\n",
    "  model = keras.Model(i, x)\n",
    "\n",
    "  model.compile(\n",
    "      optimizer=optimizer,\n",
    "      loss=loss,\n",
    "      metrics=['accuracy']\n",
    "  )\n",
    "\n",
    "  history = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=test_ds,\n",
    "    epochs=n_epochs\n",
    "  )\n",
    "  model.save(f'train_history/{name}/{idx}.keras')\n",
    "  history_df = pd.DataFrame(history.history) \n",
    "  hist_csv_file = 'train_history/' + name + '/' + str(idx) + '_history.csv'\n",
    "  with open(hist_csv_file, mode='w') as f:\n",
    "      history_df.to_csv(f)\n",
    "  plot_accuracy_and_loss(history_df, name, str(idx))\n",
    "  curr_accuracy = plot_confusion_matrix(name, str(idx))\n",
    "  accuracy.append(curr_accuracy)\n",
    "  print(f'Attempt accuracy: {curr_accuracy * 100:.2f}%')\n",
    "\n",
    "accuracy_df = pd.DataFrame(data=accuracy, columns = ['accuracy'])\n",
    "accuracy_csv_file = 'train_history/' + name + '/accuracy.csv'\n",
    "with open(accuracy_csv_file, mode='w') as f:\n",
    "    accuracy_df.to_csv(f)\n",
    "print(f'Attempts accuracy is saved to {accuracy_csv_file}')\n",
    "plot_accuracy_boxplot(accuracy, name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test 5: (2, 2) filter\n",
    "\n",
    "Same architecture as test 4, but filter is (2, 2) instead of (3, 3)\n",
    "\n",
    "Conv2D - (Batch normalization) Conv2D - (Batch normalization) MaxPooling2D - \n",
    "\n",
    "Conv2D - (Batch normalization) Conv2D - (Batch normalization) MaxPooling2D - \n",
    "\n",
    "(Flatten) Dropout - Dense (1024) - Dropout - Dense (10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempt #1\n",
      "Epoch 1/10\n",
      "4500/4500 [==============================] - 73s 16ms/step - loss: 1.5467 - accuracy: 0.4449 - val_loss: 1.3139 - val_accuracy: 0.5302\n",
      "Epoch 2/10\n",
      "4500/4500 [==============================] - 74s 16ms/step - loss: 1.2264 - accuracy: 0.5554 - val_loss: 1.1457 - val_accuracy: 0.5884\n",
      "Epoch 3/10\n",
      "4500/4500 [==============================] - 75s 17ms/step - loss: 1.0732 - accuracy: 0.6129 - val_loss: 1.0881 - val_accuracy: 0.6148\n",
      "Epoch 4/10\n",
      "4500/4500 [==============================] - 76s 17ms/step - loss: 0.9336 - accuracy: 0.6620 - val_loss: 1.0875 - val_accuracy: 0.6212\n",
      "Epoch 5/10\n",
      "4500/4500 [==============================] - 76s 17ms/step - loss: 0.7913 - accuracy: 0.7172 - val_loss: 1.0841 - val_accuracy: 0.6316\n",
      "Epoch 6/10\n",
      "4500/4500 [==============================] - 77s 17ms/step - loss: 0.6537 - accuracy: 0.7665 - val_loss: 1.1343 - val_accuracy: 0.6327\n",
      "Epoch 7/10\n",
      "4500/4500 [==============================] - 77s 17ms/step - loss: 0.5257 - accuracy: 0.8147 - val_loss: 1.2067 - val_accuracy: 0.6193\n",
      "Epoch 8/10\n",
      "4500/4500 [==============================] - 77s 17ms/step - loss: 0.4133 - accuracy: 0.8544 - val_loss: 1.2562 - val_accuracy: 0.6323\n",
      "Epoch 9/10\n",
      "4500/4500 [==============================] - 77s 17ms/step - loss: 0.3293 - accuracy: 0.8860 - val_loss: 1.3460 - val_accuracy: 0.6295\n",
      "Epoch 10/10\n",
      "4500/4500 [==============================] - 77s 17ms/step - loss: 0.2654 - accuracy: 0.9089 - val_loss: 1.4013 - val_accuracy: 0.6283\n",
      "Accuracy plot is saved to: train_history/cnn5/0_accuracy.png\n",
      "Loss plot is saved to: train_history/cnn5/0_loss.png\n",
      "563/563 [==============================] - 3s 6ms/step\n",
      "Accuracy: 62.83%\n",
      "Confusion matrix is saved to: train_history/cnn5/0_confusion_matrix.png\n",
      "Attempt accuracy: 62.83%\n",
      "Attempt #2\n",
      "Epoch 1/10\n",
      "4500/4500 [==============================] - 78s 17ms/step - loss: 1.5879 - accuracy: 0.4327 - val_loss: 1.3063 - val_accuracy: 0.5252\n",
      "Epoch 2/10\n",
      "4500/4500 [==============================] - 77s 17ms/step - loss: 1.2482 - accuracy: 0.5477 - val_loss: 1.1746 - val_accuracy: 0.5777\n",
      "Epoch 3/10\n",
      "4500/4500 [==============================] - 77s 17ms/step - loss: 1.0885 - accuracy: 0.6070 - val_loss: 1.1108 - val_accuracy: 0.6055\n",
      "Epoch 4/10\n",
      "4500/4500 [==============================] - 77s 17ms/step - loss: 0.9512 - accuracy: 0.6595 - val_loss: 1.0702 - val_accuracy: 0.6249\n",
      "Epoch 5/10\n",
      "4500/4500 [==============================] - 77s 17ms/step - loss: 0.8136 - accuracy: 0.7082 - val_loss: 1.1409 - val_accuracy: 0.6218\n",
      "Epoch 6/10\n",
      "4500/4500 [==============================] - 78s 17ms/step - loss: 0.6752 - accuracy: 0.7611 - val_loss: 1.1258 - val_accuracy: 0.6298\n",
      "Epoch 7/10\n",
      "4500/4500 [==============================] - 78s 17ms/step - loss: 0.5449 - accuracy: 0.8062 - val_loss: 1.1861 - val_accuracy: 0.6244\n",
      "Epoch 8/10\n",
      "4500/4500 [==============================] - 77s 17ms/step - loss: 0.4409 - accuracy: 0.8434 - val_loss: 1.3059 - val_accuracy: 0.6324\n",
      "Epoch 9/10\n",
      "4500/4500 [==============================] - 77s 17ms/step - loss: 0.3402 - accuracy: 0.8817 - val_loss: 1.3465 - val_accuracy: 0.6238\n",
      "Epoch 10/10\n",
      "4500/4500 [==============================] - 77s 17ms/step - loss: 0.2759 - accuracy: 0.9051 - val_loss: 1.4090 - val_accuracy: 0.6307\n",
      "Accuracy plot is saved to: train_history/cnn5/1_accuracy.png\n",
      "Loss plot is saved to: train_history/cnn5/1_loss.png\n",
      "563/563 [==============================] - 3s 6ms/step\n",
      "Accuracy: 63.07%\n",
      "Confusion matrix is saved to: train_history/cnn5/1_confusion_matrix.png\n",
      "Attempt accuracy: 63.07%\n",
      "Attempt #3\n",
      "Epoch 1/10\n",
      "4500/4500 [==============================] - 78s 17ms/step - loss: 1.5674 - accuracy: 0.4412 - val_loss: 1.2827 - val_accuracy: 0.5364\n",
      "Epoch 2/10\n",
      "4500/4500 [==============================] - 77s 17ms/step - loss: 1.2337 - accuracy: 0.5543 - val_loss: 1.1875 - val_accuracy: 0.5729\n",
      "Epoch 3/10\n",
      "4500/4500 [==============================] - 77s 17ms/step - loss: 1.0688 - accuracy: 0.6137 - val_loss: 1.1298 - val_accuracy: 0.6037\n",
      "Epoch 4/10\n",
      "4500/4500 [==============================] - 76s 17ms/step - loss: 0.9297 - accuracy: 0.6662 - val_loss: 1.1075 - val_accuracy: 0.6177\n",
      "Epoch 5/10\n",
      "4500/4500 [==============================] - 76s 17ms/step - loss: 0.7939 - accuracy: 0.7147 - val_loss: 1.1102 - val_accuracy: 0.6248\n",
      "Epoch 6/10\n",
      "4500/4500 [==============================] - 76s 17ms/step - loss: 0.6571 - accuracy: 0.7669 - val_loss: 1.2079 - val_accuracy: 0.6223\n",
      "Epoch 7/10\n",
      "4500/4500 [==============================] - 76s 17ms/step - loss: 0.5279 - accuracy: 0.8148 - val_loss: 1.2071 - val_accuracy: 0.6282\n",
      "Epoch 8/10\n",
      "4500/4500 [==============================] - 76s 17ms/step - loss: 0.4227 - accuracy: 0.8514 - val_loss: 1.2746 - val_accuracy: 0.6279\n",
      "Epoch 9/10\n",
      "4500/4500 [==============================] - 77s 17ms/step - loss: 0.3360 - accuracy: 0.8819 - val_loss: 1.3469 - val_accuracy: 0.6282\n",
      "Epoch 10/10\n",
      "4500/4500 [==============================] - 76s 17ms/step - loss: 0.2686 - accuracy: 0.9062 - val_loss: 1.3670 - val_accuracy: 0.6338\n",
      "Accuracy plot is saved to: train_history/cnn5/2_accuracy.png\n",
      "Loss plot is saved to: train_history/cnn5/2_loss.png\n",
      "563/563 [==============================] - 3s 6ms/step\n",
      "Accuracy: 63.38%\n",
      "Confusion matrix is saved to: train_history/cnn5/2_confusion_matrix.png\n",
      "Attempt accuracy: 63.38%\n",
      "Attempt #4\n",
      "Epoch 1/10\n",
      "4500/4500 [==============================] - 78s 17ms/step - loss: 1.5673 - accuracy: 0.4399 - val_loss: 1.3704 - val_accuracy: 0.5128\n",
      "Epoch 2/10\n",
      "4500/4500 [==============================] - 77s 17ms/step - loss: 1.2349 - accuracy: 0.5513 - val_loss: 1.1528 - val_accuracy: 0.5816\n",
      "Epoch 3/10\n",
      "4500/4500 [==============================] - 77s 17ms/step - loss: 1.0793 - accuracy: 0.6114 - val_loss: 1.1105 - val_accuracy: 0.6013\n",
      "Epoch 4/10\n",
      "4500/4500 [==============================] - 77s 17ms/step - loss: 0.9475 - accuracy: 0.6603 - val_loss: 1.0815 - val_accuracy: 0.6213\n",
      "Epoch 5/10\n",
      "4500/4500 [==============================] - 77s 17ms/step - loss: 0.8075 - accuracy: 0.7103 - val_loss: 1.1087 - val_accuracy: 0.6209\n",
      "Epoch 6/10\n",
      "4500/4500 [==============================] - 77s 17ms/step - loss: 0.6737 - accuracy: 0.7621 - val_loss: 1.1395 - val_accuracy: 0.6288\n",
      "Epoch 7/10\n",
      "4500/4500 [==============================] - 77s 17ms/step - loss: 0.5412 - accuracy: 0.8103 - val_loss: 1.2123 - val_accuracy: 0.6252\n",
      "Epoch 8/10\n",
      "4500/4500 [==============================] - 77s 17ms/step - loss: 0.4297 - accuracy: 0.8496 - val_loss: 1.2876 - val_accuracy: 0.6356\n",
      "Epoch 9/10\n",
      "4500/4500 [==============================] - 77s 17ms/step - loss: 0.3419 - accuracy: 0.8814 - val_loss: 1.3373 - val_accuracy: 0.6343\n",
      "Epoch 10/10\n",
      "4500/4500 [==============================] - 77s 17ms/step - loss: 0.2775 - accuracy: 0.9037 - val_loss: 1.4585 - val_accuracy: 0.6289\n",
      "Accuracy plot is saved to: train_history/cnn5/3_accuracy.png\n",
      "Loss plot is saved to: train_history/cnn5/3_loss.png\n",
      "563/563 [==============================] - 4s 6ms/step\n",
      "Accuracy: 62.89%\n",
      "Confusion matrix is saved to: train_history/cnn5/3_confusion_matrix.png\n",
      "Attempt accuracy: 62.89%\n",
      "Attempt #5\n",
      "Epoch 1/10\n",
      "4500/4500 [==============================] - 78s 17ms/step - loss: 1.5876 - accuracy: 0.4330 - val_loss: 1.2978 - val_accuracy: 0.5299\n",
      "Epoch 2/10\n",
      "4500/4500 [==============================] - 77s 17ms/step - loss: 1.2424 - accuracy: 0.5482 - val_loss: 1.1429 - val_accuracy: 0.5878\n",
      "Epoch 3/10\n",
      "4500/4500 [==============================] - 77s 17ms/step - loss: 1.0806 - accuracy: 0.6118 - val_loss: 1.1015 - val_accuracy: 0.6044\n",
      "Epoch 4/10\n",
      "4500/4500 [==============================] - 76s 17ms/step - loss: 0.9454 - accuracy: 0.6605 - val_loss: 1.0865 - val_accuracy: 0.6154\n",
      "Epoch 5/10\n",
      "4500/4500 [==============================] - 77s 17ms/step - loss: 0.8064 - accuracy: 0.7120 - val_loss: 1.0929 - val_accuracy: 0.6236\n",
      "Epoch 6/10\n",
      "4500/4500 [==============================] - 76s 17ms/step - loss: 0.6676 - accuracy: 0.7637 - val_loss: 1.1087 - val_accuracy: 0.6359\n",
      "Epoch 7/10\n",
      "4500/4500 [==============================] - 76s 17ms/step - loss: 0.5362 - accuracy: 0.8122 - val_loss: 1.1492 - val_accuracy: 0.6391\n",
      "Epoch 8/10\n",
      "4500/4500 [==============================] - 76s 17ms/step - loss: 0.4250 - accuracy: 0.8514 - val_loss: 1.2044 - val_accuracy: 0.6433\n",
      "Epoch 9/10\n",
      "4500/4500 [==============================] - 77s 17ms/step - loss: 0.3419 - accuracy: 0.8813 - val_loss: 1.2682 - val_accuracy: 0.6368\n",
      "Epoch 10/10\n",
      "4500/4500 [==============================] - 77s 17ms/step - loss: 0.2763 - accuracy: 0.9030 - val_loss: 1.3177 - val_accuracy: 0.6331\n",
      "Accuracy plot is saved to: train_history/cnn5/4_accuracy.png\n",
      "Loss plot is saved to: train_history/cnn5/4_loss.png\n",
      "563/563 [==============================] - 3s 6ms/step\n",
      "Accuracy: 63.31%\n",
      "Confusion matrix is saved to: train_history/cnn5/4_confusion_matrix.png\n",
      "Attempt accuracy: 63.31%\n",
      "Attempts accuracy is saved to train_history/cnn5/accuracy.csv\n",
      "Accuracy boxplot is saved to: train_history/cnn5/boxplot.png\n"
     ]
    }
   ],
   "source": [
    "name = 'cnn5'\n",
    "n_epochs = 10\n",
    "optimizer = 'adamax'\n",
    "loss = 'sparse_categorical_crossentropy'\n",
    "n_repeat = 5\n",
    "filter = (2, 2)\n",
    "\n",
    "keras.utils.set_random_seed(seed_value)\n",
    "\n",
    "accuracy = []\n",
    "for idx in range(n_repeat):\n",
    "  print(f'Attempt #{idx + 1}')\n",
    "  i = keras.Input(shape=input_shape)\n",
    "  x = keras.layers.Conv2D(32, filter, activation='relu', padding='same')(i)\n",
    "  x = keras.layers.BatchNormalization()(x)\n",
    "  x = keras.layers.Conv2D(32, filter, activation='relu', padding='same')(x)\n",
    "  x = keras.layers.BatchNormalization()(x)\n",
    "  x = keras.layers.MaxPooling2D((2, 2))(x)\n",
    "\n",
    "  x = keras.layers.Conv2D(64, filter, activation='relu', padding='same')(x)\n",
    "  x = keras.layers.BatchNormalization()(x)\n",
    "  x = keras.layers.Conv2D(64, filter, activation='relu', padding='same')(x)\n",
    "  x = keras.layers.BatchNormalization()(x)\n",
    "  x = keras.layers.MaxPooling2D((2, 2))(x)\n",
    "\n",
    "  x = keras.layers.Flatten()(x)\n",
    "  x = keras.layers.Dropout(0.2)(x)\n",
    "  x = keras.layers.Dense(1024, activation='relu')(x)\n",
    "  x = keras.layers.Dropout(0.2)(x)\n",
    "  x = keras.layers.Dense(n_classes, activation='softmax')(x)\n",
    "  model = keras.Model(i, x)\n",
    "\n",
    "  model.compile(\n",
    "      optimizer=optimizer,\n",
    "      loss=loss,\n",
    "      metrics=['accuracy']\n",
    "  )\n",
    "\n",
    "  history = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=test_ds,\n",
    "    epochs=n_epochs\n",
    "  )\n",
    "  model.save(f'train_history/{name}/{idx}.keras')\n",
    "  history_df = pd.DataFrame(history.history) \n",
    "  hist_csv_file = 'train_history/' + name + '/' + str(idx) + '_history.csv'\n",
    "  with open(hist_csv_file, mode='w') as f:\n",
    "      history_df.to_csv(f)\n",
    "  plot_accuracy_and_loss(history_df, name, str(idx))\n",
    "  curr_accuracy = plot_confusion_matrix(name, str(idx))\n",
    "  accuracy.append(curr_accuracy)\n",
    "  print(f'Attempt accuracy: {curr_accuracy * 100:.2f}%')\n",
    "\n",
    "accuracy_df = pd.DataFrame(data=accuracy, columns = ['accuracy'])\n",
    "accuracy_csv_file = 'train_history/' + name + '/accuracy.csv'\n",
    "with open(accuracy_csv_file, mode='w') as f:\n",
    "    accuracy_df.to_csv(f)\n",
    "print(f'Attempts accuracy is saved to {accuracy_csv_file}')\n",
    "plot_accuracy_boxplot(accuracy, name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test 6. 6 convolutional layers\n",
    "Conv2D - (Batch normalization) Conv2D - (Batch normalization) MaxPooling2D - \n",
    "\n",
    "Conv2D - (Batch normalization) Conv2D - (Batch normalization) MaxPooling2D - \n",
    "\n",
    "Conv2D - (Batch normalization) Conv2D - (Batch normalization) MaxPooling2D - \n",
    "\n",
    "(Flatten) Dropout - Dense (1024) - Dropout - Dense (10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempt #1\n",
      "Epoch 1/10\n",
      "4500/4500 [==============================] - 118s 26ms/step - loss: 1.5801 - accuracy: 0.4330 - val_loss: 1.2883 - val_accuracy: 0.5324\n",
      "Epoch 2/10\n",
      "4500/4500 [==============================] - 94s 21ms/step - loss: 1.2044 - accuracy: 0.5652 - val_loss: 1.1055 - val_accuracy: 0.6012\n",
      "Epoch 3/10\n",
      "4500/4500 [==============================] - 98s 22ms/step - loss: 1.0420 - accuracy: 0.6229 - val_loss: 1.0035 - val_accuracy: 0.6410\n",
      "Epoch 4/10\n",
      "4500/4500 [==============================] - 105s 23ms/step - loss: 0.9198 - accuracy: 0.6697 - val_loss: 0.9806 - val_accuracy: 0.6507\n",
      "Epoch 5/10\n",
      "4500/4500 [==============================] - 121s 27ms/step - loss: 0.8132 - accuracy: 0.7049 - val_loss: 0.9851 - val_accuracy: 0.6553\n",
      "Epoch 6/10\n",
      "4500/4500 [==============================] - 100s 22ms/step - loss: 0.7140 - accuracy: 0.7409 - val_loss: 0.9725 - val_accuracy: 0.6678\n",
      "Epoch 7/10\n",
      "4500/4500 [==============================] - 98s 22ms/step - loss: 0.6225 - accuracy: 0.7763 - val_loss: 1.0141 - val_accuracy: 0.6618\n",
      "Epoch 8/10\n",
      "4500/4500 [==============================] - 99s 22ms/step - loss: 0.5391 - accuracy: 0.8046 - val_loss: 0.9845 - val_accuracy: 0.6844\n",
      "Epoch 9/10\n",
      "4500/4500 [==============================] - 99s 22ms/step - loss: 0.4640 - accuracy: 0.8326 - val_loss: 1.0488 - val_accuracy: 0.6789\n",
      "Epoch 10/10\n",
      "4500/4500 [==============================] - 99s 22ms/step - loss: 0.3940 - accuracy: 0.8591 - val_loss: 1.0926 - val_accuracy: 0.6833\n",
      "Accuracy plot is saved to: train_history/cnn6/0_accuracy.png\n",
      "Loss plot is saved to: train_history/cnn6/0_loss.png\n",
      "563/563 [==============================] - 6s 10ms/step\n",
      "Accuracy: 68.33%\n",
      "Confusion matrix is saved to: train_history/cnn6/0_confusion_matrix.png\n",
      "Attempt accuracy: 68.33%\n",
      "Attempt #2\n",
      "Epoch 1/10\n",
      "4500/4500 [==============================] - 101s 22ms/step - loss: 1.5551 - accuracy: 0.4399 - val_loss: 1.3000 - val_accuracy: 0.5316\n",
      "Epoch 2/10\n",
      "4500/4500 [==============================] - 100s 22ms/step - loss: 1.1955 - accuracy: 0.5693 - val_loss: 1.0888 - val_accuracy: 0.6113\n",
      "Epoch 3/10\n",
      "4500/4500 [==============================] - 99s 22ms/step - loss: 1.0325 - accuracy: 0.6284 - val_loss: 1.0996 - val_accuracy: 0.6182\n",
      "Epoch 4/10\n",
      "4500/4500 [==============================] - 98s 22ms/step - loss: 0.9082 - accuracy: 0.6727 - val_loss: 1.0130 - val_accuracy: 0.6488\n",
      "Epoch 5/10\n",
      "4500/4500 [==============================] - 97s 22ms/step - loss: 0.8042 - accuracy: 0.7096 - val_loss: 1.0475 - val_accuracy: 0.6437\n",
      "Epoch 6/10\n",
      "4500/4500 [==============================] - 98s 22ms/step - loss: 0.7081 - accuracy: 0.7463 - val_loss: 0.9685 - val_accuracy: 0.6766\n",
      "Epoch 7/10\n",
      "4500/4500 [==============================] - 99s 22ms/step - loss: 0.6112 - accuracy: 0.7791 - val_loss: 1.0188 - val_accuracy: 0.6713\n",
      "Epoch 8/10\n",
      "4500/4500 [==============================] - 99s 22ms/step - loss: 0.5302 - accuracy: 0.8080 - val_loss: 1.0037 - val_accuracy: 0.6838\n",
      "Epoch 9/10\n",
      "4500/4500 [==============================] - 99s 22ms/step - loss: 0.4511 - accuracy: 0.8378 - val_loss: 1.0408 - val_accuracy: 0.6868\n",
      "Epoch 10/10\n",
      "4500/4500 [==============================] - 100s 22ms/step - loss: 0.3837 - accuracy: 0.8619 - val_loss: 1.1030 - val_accuracy: 0.6799\n",
      "Accuracy plot is saved to: train_history/cnn6/1_accuracy.png\n",
      "Loss plot is saved to: train_history/cnn6/1_loss.png\n",
      "563/563 [==============================] - 5s 9ms/step\n",
      "Accuracy: 67.99%\n",
      "Confusion matrix is saved to: train_history/cnn6/1_confusion_matrix.png\n",
      "Attempt accuracy: 67.99%\n",
      "Attempt #3\n",
      "Epoch 1/10\n",
      "4500/4500 [==============================] - 101s 22ms/step - loss: 1.5630 - accuracy: 0.4390 - val_loss: 1.2681 - val_accuracy: 0.5427\n",
      "Epoch 2/10\n",
      "4500/4500 [==============================] - 100s 22ms/step - loss: 1.2104 - accuracy: 0.5612 - val_loss: 1.1188 - val_accuracy: 0.6031\n",
      "Epoch 3/10\n",
      "4500/4500 [==============================] - 100s 22ms/step - loss: 1.0497 - accuracy: 0.6223 - val_loss: 1.0650 - val_accuracy: 0.6274\n",
      "Epoch 4/10\n",
      "4500/4500 [==============================] - 100s 22ms/step - loss: 0.9255 - accuracy: 0.6686 - val_loss: 0.9918 - val_accuracy: 0.6514\n",
      "Epoch 5/10\n",
      "4500/4500 [==============================] - 100s 22ms/step - loss: 0.8222 - accuracy: 0.7039 - val_loss: 0.9846 - val_accuracy: 0.6627\n",
      "Epoch 6/10\n",
      "4500/4500 [==============================] - 100s 22ms/step - loss: 0.7220 - accuracy: 0.7393 - val_loss: 0.9726 - val_accuracy: 0.6746\n",
      "Epoch 7/10\n",
      "4500/4500 [==============================] - 100s 22ms/step - loss: 0.6256 - accuracy: 0.7735 - val_loss: 0.9865 - val_accuracy: 0.6749\n",
      "Epoch 8/10\n",
      "4500/4500 [==============================] - 100s 22ms/step - loss: 0.5361 - accuracy: 0.8066 - val_loss: 1.0570 - val_accuracy: 0.6808\n",
      "Epoch 9/10\n",
      "4500/4500 [==============================] - 100s 22ms/step - loss: 0.4604 - accuracy: 0.8347 - val_loss: 1.0991 - val_accuracy: 0.6804\n",
      "Epoch 10/10\n",
      "4500/4500 [==============================] - 100s 22ms/step - loss: 0.3970 - accuracy: 0.8582 - val_loss: 1.1293 - val_accuracy: 0.6786\n",
      "Accuracy plot is saved to: train_history/cnn6/2_accuracy.png\n",
      "Loss plot is saved to: train_history/cnn6/2_loss.png\n",
      "563/563 [==============================] - 6s 10ms/step\n",
      "Accuracy: 67.86%\n",
      "Confusion matrix is saved to: train_history/cnn6/2_confusion_matrix.png\n",
      "Attempt accuracy: 67.86%\n",
      "Attempt #4\n",
      "Epoch 1/10\n",
      "4500/4500 [==============================] - 102s 23ms/step - loss: 1.5704 - accuracy: 0.4374 - val_loss: 1.2910 - val_accuracy: 0.5361\n",
      "Epoch 2/10\n",
      "4500/4500 [==============================] - 101s 22ms/step - loss: 1.1939 - accuracy: 0.5672 - val_loss: 1.1073 - val_accuracy: 0.6003\n",
      "Epoch 3/10\n",
      "4500/4500 [==============================] - 101s 22ms/step - loss: 1.0303 - accuracy: 0.6284 - val_loss: 1.0302 - val_accuracy: 0.6355\n",
      "Epoch 4/10\n",
      "4500/4500 [==============================] - 101s 22ms/step - loss: 0.9125 - accuracy: 0.6726 - val_loss: 1.0009 - val_accuracy: 0.6501\n",
      "Epoch 5/10\n",
      "4500/4500 [==============================] - 101s 22ms/step - loss: 0.8047 - accuracy: 0.7095 - val_loss: 0.9756 - val_accuracy: 0.6657\n",
      "Epoch 6/10\n",
      "4500/4500 [==============================] - 101s 22ms/step - loss: 0.7063 - accuracy: 0.7449 - val_loss: 0.9974 - val_accuracy: 0.6676\n",
      "Epoch 7/10\n",
      "4500/4500 [==============================] - 101s 23ms/step - loss: 0.6144 - accuracy: 0.7779 - val_loss: 0.9834 - val_accuracy: 0.6739\n",
      "Epoch 8/10\n",
      "4500/4500 [==============================] - 101s 22ms/step - loss: 0.5275 - accuracy: 0.8102 - val_loss: 1.0938 - val_accuracy: 0.6560\n",
      "Epoch 9/10\n",
      "4500/4500 [==============================] - 101s 22ms/step - loss: 0.4503 - accuracy: 0.8378 - val_loss: 1.0837 - val_accuracy: 0.6742\n",
      "Epoch 10/10\n",
      "4500/4500 [==============================] - 101s 22ms/step - loss: 0.3885 - accuracy: 0.8603 - val_loss: 1.1215 - val_accuracy: 0.6818\n",
      "Accuracy plot is saved to: train_history/cnn6/3_accuracy.png\n",
      "Loss plot is saved to: train_history/cnn6/3_loss.png\n",
      "563/563 [==============================] - 6s 10ms/step\n",
      "Accuracy: 68.18%\n",
      "Confusion matrix is saved to: train_history/cnn6/3_confusion_matrix.png\n",
      "Attempt accuracy: 68.18%\n",
      "Attempt #5\n",
      "Epoch 1/10\n",
      "4500/4500 [==============================] - 101s 22ms/step - loss: 1.5595 - accuracy: 0.4383 - val_loss: 1.2262 - val_accuracy: 0.5529\n",
      "Epoch 2/10\n",
      "4500/4500 [==============================] - 100s 22ms/step - loss: 1.1958 - accuracy: 0.5662 - val_loss: 1.0842 - val_accuracy: 0.6085\n",
      "Epoch 3/10\n",
      "4500/4500 [==============================] - 100s 22ms/step - loss: 1.0295 - accuracy: 0.6306 - val_loss: 1.0152 - val_accuracy: 0.6413\n",
      "Epoch 4/10\n",
      "4500/4500 [==============================] - 100s 22ms/step - loss: 0.9071 - accuracy: 0.6743 - val_loss: 0.9824 - val_accuracy: 0.6542\n",
      "Epoch 5/10\n",
      "4500/4500 [==============================] - 100s 22ms/step - loss: 0.8018 - accuracy: 0.7117 - val_loss: 0.9368 - val_accuracy: 0.6733\n",
      "Epoch 6/10\n",
      "4500/4500 [==============================] - 100s 22ms/step - loss: 0.6974 - accuracy: 0.7485 - val_loss: 1.0276 - val_accuracy: 0.6607\n",
      "Epoch 7/10\n",
      "4500/4500 [==============================] - 100s 22ms/step - loss: 0.6038 - accuracy: 0.7818 - val_loss: 0.9818 - val_accuracy: 0.6764\n",
      "Epoch 8/10\n",
      "4500/4500 [==============================] - 100s 22ms/step - loss: 0.5175 - accuracy: 0.8146 - val_loss: 1.0462 - val_accuracy: 0.6733\n",
      "Epoch 9/10\n",
      "4500/4500 [==============================] - 100s 22ms/step - loss: 0.4410 - accuracy: 0.8401 - val_loss: 1.0920 - val_accuracy: 0.6780\n",
      "Epoch 10/10\n",
      "4500/4500 [==============================] - 100s 22ms/step - loss: 0.3747 - accuracy: 0.8650 - val_loss: 1.1231 - val_accuracy: 0.6803\n",
      "Accuracy plot is saved to: train_history/cnn6/4_accuracy.png\n",
      "Loss plot is saved to: train_history/cnn6/4_loss.png\n",
      "563/563 [==============================] - 6s 10ms/step\n",
      "Accuracy: 68.03%\n",
      "Confusion matrix is saved to: train_history/cnn6/4_confusion_matrix.png\n",
      "Attempt accuracy: 68.03%\n",
      "Attempts accuracy is saved to train_history/cnn6/accuracy.csv\n",
      "Accuracy boxplot is saved to: train_history/cnn6/boxplot.png\n"
     ]
    }
   ],
   "source": [
    "name = 'cnn6'\n",
    "n_epochs = 10\n",
    "optimizer = 'adamax'\n",
    "loss = 'sparse_categorical_crossentropy'\n",
    "n_repeat = 5\n",
    "filter = (3, 3)\n",
    "\n",
    "keras.utils.set_random_seed(seed_value)\n",
    "\n",
    "accuracy = []\n",
    "for idx in range(n_repeat):\n",
    "  print(f'Attempt #{idx + 1}')\n",
    "  i = keras.Input(shape=input_shape)\n",
    "  x = keras.layers.Conv2D(32, filter, activation='relu', padding='same')(i)\n",
    "  x = keras.layers.BatchNormalization()(x)\n",
    "  x = keras.layers.Conv2D(32, filter, activation='relu', padding='same')(x)\n",
    "  x = keras.layers.BatchNormalization()(x)\n",
    "  x = keras.layers.MaxPooling2D((2, 2))(x)\n",
    "\n",
    "  x = keras.layers.Conv2D(64, filter, activation='relu', padding='same')(x)\n",
    "  x = keras.layers.BatchNormalization()(x)\n",
    "  x = keras.layers.Conv2D(64, filter, activation='relu', padding='same')(x)\n",
    "  x = keras.layers.BatchNormalization()(x)\n",
    "  x = keras.layers.MaxPooling2D((2, 2))(x)\n",
    "\n",
    "  x = keras.layers.Conv2D(128, filter, activation='relu', padding='same')(x)\n",
    "  x = keras.layers.BatchNormalization()(x)\n",
    "  x = keras.layers.Conv2D(128, filter, activation='relu', padding='same')(x)\n",
    "  x = keras.layers.BatchNormalization()(x)\n",
    "  x = keras.layers.MaxPooling2D((2, 2))(x)\n",
    "\n",
    "  x = keras.layers.Flatten()(x)\n",
    "  x = keras.layers.Dropout(0.2)(x)\n",
    "  x = keras.layers.Dense(1024, activation='relu')(x)\n",
    "  x = keras.layers.Dropout(0.2)(x)\n",
    "  x = keras.layers.Dense(n_classes, activation='softmax')(x)\n",
    "  model = keras.Model(i, x)\n",
    "\n",
    "  model.compile(\n",
    "      optimizer=optimizer,\n",
    "      loss=loss,\n",
    "      metrics=['accuracy']\n",
    "  )\n",
    "\n",
    "  history = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=test_ds,\n",
    "    epochs=n_epochs\n",
    "  )\n",
    "  model.save(f'train_history/{name}/{idx}.keras')\n",
    "  history_df = pd.DataFrame(history.history) \n",
    "  hist_csv_file = 'train_history/' + name + '/' + str(idx) + '_history.csv'\n",
    "  with open(hist_csv_file, mode='w') as f:\n",
    "      history_df.to_csv(f)\n",
    "  plot_accuracy_and_loss(history_df, name, str(idx))\n",
    "  curr_accuracy = plot_confusion_matrix(name, str(idx))\n",
    "  accuracy.append(curr_accuracy)\n",
    "  print(f'Attempt accuracy: {curr_accuracy * 100:.2f}%')\n",
    "\n",
    "accuracy_df = pd.DataFrame(data=accuracy, columns = ['accuracy'])\n",
    "accuracy_csv_file = 'train_history/' + name + '/accuracy.csv'\n",
    "with open(accuracy_csv_file, mode='w') as f:\n",
    "    accuracy_df.to_csv(f)\n",
    "print(f'Attempts accuracy is saved to {accuracy_csv_file}')\n",
    "plot_accuracy_boxplot(accuracy, name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test 7. Optimizer Nadam\n",
    "\n",
    "Same architecture\n",
    "\n",
    "Conv2D - (Batch normalization) Conv2D - (Batch normalization) MaxPooling2D - \n",
    "\n",
    "Conv2D - (Batch normalization) Conv2D - (Batch normalization) MaxPooling2D - \n",
    "\n",
    "Conv2D - (Batch normalization) Conv2D - (Batch normalization) MaxPooling2D - \n",
    "\n",
    "(Flatten) Dropout - Dense (1024) - Dropout - Dense (10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempt #1\n",
      "Epoch 1/10\n",
      "4500/4500 [==============================] - 130s 28ms/step - loss: 1.5782 - accuracy: 0.4302 - val_loss: 1.5742 - val_accuracy: 0.4326\n",
      "Epoch 2/10\n",
      "4500/4500 [==============================] - 107s 24ms/step - loss: 1.2644 - accuracy: 0.5462 - val_loss: 1.1450 - val_accuracy: 0.5876\n",
      "Epoch 3/10\n",
      "4500/4500 [==============================] - 109s 24ms/step - loss: 1.1148 - accuracy: 0.6022 - val_loss: 1.0764 - val_accuracy: 0.6240\n",
      "Epoch 4/10\n",
      "4500/4500 [==============================] - 110s 24ms/step - loss: 1.0018 - accuracy: 0.6421 - val_loss: 1.0626 - val_accuracy: 0.6286\n",
      "Epoch 5/10\n",
      "4500/4500 [==============================] - 111s 25ms/step - loss: 0.9047 - accuracy: 0.6757 - val_loss: 0.9588 - val_accuracy: 0.6619\n",
      "Epoch 6/10\n",
      "4500/4500 [==============================] - 110s 24ms/step - loss: 0.8231 - accuracy: 0.7049 - val_loss: 0.9478 - val_accuracy: 0.6727\n",
      "Epoch 7/10\n",
      "4500/4500 [==============================] - 111s 25ms/step - loss: 0.7419 - accuracy: 0.7342 - val_loss: 0.9726 - val_accuracy: 0.6776\n",
      "Epoch 8/10\n",
      "4500/4500 [==============================] - 111s 25ms/step - loss: 0.6624 - accuracy: 0.7628 - val_loss: 1.0109 - val_accuracy: 0.6743\n",
      "Epoch 9/10\n",
      "4500/4500 [==============================] - 110s 24ms/step - loss: 0.5928 - accuracy: 0.7877 - val_loss: 1.0432 - val_accuracy: 0.6802\n",
      "Epoch 10/10\n",
      "4500/4500 [==============================] - 111s 25ms/step - loss: 0.5257 - accuracy: 0.8118 - val_loss: 1.1260 - val_accuracy: 0.6626\n",
      "Accuracy plot is saved to: train_history/cnn7/0_accuracy.png\n",
      "Loss plot is saved to: train_history/cnn7/0_loss.png\n",
      "563/563 [==============================] - 6s 10ms/step\n",
      "Accuracy: 66.26%\n",
      "Confusion matrix is saved to: train_history/cnn7/0_confusion_matrix.png\n",
      "Attempt accuracy: 66.26%\n",
      "Attempt #2\n",
      "Epoch 1/10\n",
      "4500/4500 [==============================] - 115s 25ms/step - loss: 1.8209 - accuracy: 0.3591 - val_loss: 1.4683 - val_accuracy: 0.4557\n",
      "Epoch 2/10\n",
      "4500/4500 [==============================] - 112s 25ms/step - loss: 1.3864 - accuracy: 0.4941 - val_loss: 1.2293 - val_accuracy: 0.5568\n",
      "Epoch 3/10\n",
      "4500/4500 [==============================] - 112s 25ms/step - loss: 1.2130 - accuracy: 0.5659 - val_loss: 1.0984 - val_accuracy: 0.6003\n",
      "Epoch 4/10\n",
      "4500/4500 [==============================] - 112s 25ms/step - loss: 1.0953 - accuracy: 0.6080 - val_loss: 1.0722 - val_accuracy: 0.6164\n",
      "Epoch 5/10\n",
      "4500/4500 [==============================] - 112s 25ms/step - loss: 1.0043 - accuracy: 0.6391 - val_loss: 1.0193 - val_accuracy: 0.6419\n",
      "Epoch 6/10\n",
      "4500/4500 [==============================] - 111s 25ms/step - loss: 0.9179 - accuracy: 0.6703 - val_loss: 0.9627 - val_accuracy: 0.6605\n",
      "Epoch 7/10\n",
      "4500/4500 [==============================] - 110s 25ms/step - loss: 0.8408 - accuracy: 0.6990 - val_loss: 1.0070 - val_accuracy: 0.6511\n",
      "Epoch 8/10\n",
      "4500/4500 [==============================] - 112s 25ms/step - loss: 0.7605 - accuracy: 0.7270 - val_loss: 0.9718 - val_accuracy: 0.6642\n",
      "Epoch 9/10\n",
      "4500/4500 [==============================] - 112s 25ms/step - loss: 0.6926 - accuracy: 0.7515 - val_loss: 1.0147 - val_accuracy: 0.6694\n",
      "Epoch 10/10\n",
      "4500/4500 [==============================] - 111s 25ms/step - loss: 0.6265 - accuracy: 0.7741 - val_loss: 1.0319 - val_accuracy: 0.6678\n",
      "Accuracy plot is saved to: train_history/cnn7/1_accuracy.png\n",
      "Loss plot is saved to: train_history/cnn7/1_loss.png\n",
      "WARNING:tensorflow:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n",
      "563/563 [==============================] - 6s 10ms/step\n",
      "Accuracy: 66.78%\n",
      "Confusion matrix is saved to: train_history/cnn7/1_confusion_matrix.png\n",
      "Attempt accuracy: 66.78%\n",
      "Attempt #3\n",
      "Epoch 1/10\n",
      "4500/4500 [==============================] - 115s 25ms/step - loss: 1.7835 - accuracy: 0.3728 - val_loss: 1.4141 - val_accuracy: 0.4782\n",
      "Epoch 2/10\n",
      "4500/4500 [==============================] - 113s 25ms/step - loss: 1.3680 - accuracy: 0.4999 - val_loss: 1.3326 - val_accuracy: 0.5237\n",
      "Epoch 3/10\n",
      "4500/4500 [==============================] - 113s 25ms/step - loss: 1.2098 - accuracy: 0.5643 - val_loss: 1.1304 - val_accuracy: 0.5917\n",
      "Epoch 4/10\n",
      "4500/4500 [==============================] - 113s 25ms/step - loss: 1.0958 - accuracy: 0.6063 - val_loss: 1.0772 - val_accuracy: 0.6213\n",
      "Epoch 5/10\n",
      "4500/4500 [==============================] - 113s 25ms/step - loss: 1.0067 - accuracy: 0.6410 - val_loss: 1.0335 - val_accuracy: 0.6362\n",
      "Epoch 6/10\n",
      "4500/4500 [==============================] - 113s 25ms/step - loss: 0.9264 - accuracy: 0.6686 - val_loss: 0.9775 - val_accuracy: 0.6603\n",
      "Epoch 7/10\n",
      "4500/4500 [==============================] - 113s 25ms/step - loss: 0.8539 - accuracy: 0.6920 - val_loss: 1.0091 - val_accuracy: 0.6544\n",
      "Epoch 8/10\n",
      "4500/4500 [==============================] - 113s 25ms/step - loss: 0.7785 - accuracy: 0.7186 - val_loss: 0.9631 - val_accuracy: 0.6717\n",
      "Epoch 9/10\n",
      "4500/4500 [==============================] - 113s 25ms/step - loss: 0.7144 - accuracy: 0.7439 - val_loss: 0.9974 - val_accuracy: 0.6748\n",
      "Epoch 10/10\n",
      "4500/4500 [==============================] - 112s 25ms/step - loss: 0.6534 - accuracy: 0.7656 - val_loss: 1.0605 - val_accuracy: 0.6698\n",
      "Accuracy plot is saved to: train_history/cnn7/2_accuracy.png\n",
      "Loss plot is saved to: train_history/cnn7/2_loss.png\n",
      "WARNING:tensorflow:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n",
      "563/563 [==============================] - 6s 10ms/step\n",
      "Accuracy: 66.98%\n",
      "Confusion matrix is saved to: train_history/cnn7/2_confusion_matrix.png\n",
      "Attempt accuracy: 66.98%\n",
      "Attempt #4\n",
      "Epoch 1/10\n",
      "4500/4500 [==============================] - 116s 25ms/step - loss: 1.8372 - accuracy: 0.3551 - val_loss: 1.4612 - val_accuracy: 0.4683\n",
      "Epoch 2/10\n",
      "4500/4500 [==============================] - 114s 25ms/step - loss: 1.3764 - accuracy: 0.4968 - val_loss: 1.2118 - val_accuracy: 0.5595\n",
      "Epoch 3/10\n",
      "4500/4500 [==============================] - 113s 25ms/step - loss: 1.2039 - accuracy: 0.5661 - val_loss: 1.0818 - val_accuracy: 0.6120\n",
      "Epoch 4/10\n",
      "4500/4500 [==============================] - 114s 25ms/step - loss: 1.0807 - accuracy: 0.6144 - val_loss: 1.0597 - val_accuracy: 0.6303\n",
      "Epoch 5/10\n",
      "4500/4500 [==============================] - 113s 25ms/step - loss: 0.9838 - accuracy: 0.6486 - val_loss: 0.9856 - val_accuracy: 0.6541\n",
      "Epoch 6/10\n",
      "4500/4500 [==============================] - 113s 25ms/step - loss: 0.8997 - accuracy: 0.6787 - val_loss: 0.9837 - val_accuracy: 0.6529\n",
      "Epoch 7/10\n",
      "4500/4500 [==============================] - 113s 25ms/step - loss: 0.8229 - accuracy: 0.7058 - val_loss: 0.9416 - val_accuracy: 0.6703\n",
      "Epoch 8/10\n",
      "4500/4500 [==============================] - 114s 25ms/step - loss: 0.7513 - accuracy: 0.7288 - val_loss: 0.9667 - val_accuracy: 0.6752\n",
      "Epoch 9/10\n",
      "4500/4500 [==============================] - 114s 25ms/step - loss: 0.6773 - accuracy: 0.7553 - val_loss: 0.9777 - val_accuracy: 0.6724\n",
      "Epoch 10/10\n",
      "4500/4500 [==============================] - 113s 25ms/step - loss: 0.6110 - accuracy: 0.7805 - val_loss: 0.9927 - val_accuracy: 0.6718\n",
      "Accuracy plot is saved to: train_history/cnn7/3_accuracy.png\n",
      "Loss plot is saved to: train_history/cnn7/3_loss.png\n",
      "WARNING:tensorflow:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n",
      "563/563 [==============================] - 6s 10ms/step\n",
      "Accuracy: 67.18%\n",
      "Confusion matrix is saved to: train_history/cnn7/3_confusion_matrix.png\n",
      "Attempt accuracy: 67.18%\n",
      "Attempt #5\n",
      "Epoch 1/10\n",
      "4500/4500 [==============================] - 115s 25ms/step - loss: 1.8997 - accuracy: 0.3067 - val_loss: 1.7356 - val_accuracy: 0.3706\n",
      "Epoch 2/10\n",
      "4500/4500 [==============================] - 113s 25ms/step - loss: 1.4600 - accuracy: 0.4616 - val_loss: 1.2858 - val_accuracy: 0.5336\n",
      "Epoch 3/10\n",
      "4500/4500 [==============================] - 113s 25ms/step - loss: 1.2602 - accuracy: 0.5460 - val_loss: 1.1609 - val_accuracy: 0.5787\n",
      "Epoch 4/10\n",
      "4500/4500 [==============================] - 113s 25ms/step - loss: 1.1364 - accuracy: 0.5940 - val_loss: 1.0670 - val_accuracy: 0.6216\n",
      "Epoch 5/10\n",
      "4500/4500 [==============================] - 113s 25ms/step - loss: 1.0304 - accuracy: 0.6299 - val_loss: 1.0209 - val_accuracy: 0.6390\n",
      "Epoch 6/10\n",
      "4500/4500 [==============================] - 114s 25ms/step - loss: 0.9440 - accuracy: 0.6623 - val_loss: 0.9869 - val_accuracy: 0.6588\n",
      "Epoch 7/10\n",
      "4500/4500 [==============================] - 113s 25ms/step - loss: 0.8722 - accuracy: 0.6906 - val_loss: 0.9514 - val_accuracy: 0.6680\n",
      "Epoch 8/10\n",
      "4500/4500 [==============================] - 113s 25ms/step - loss: 0.7975 - accuracy: 0.7132 - val_loss: 0.9659 - val_accuracy: 0.6724\n",
      "Epoch 9/10\n",
      "4500/4500 [==============================] - 114s 25ms/step - loss: 0.7318 - accuracy: 0.7371 - val_loss: 0.9661 - val_accuracy: 0.6752\n",
      "Epoch 10/10\n",
      "4500/4500 [==============================] - 113s 25ms/step - loss: 0.6662 - accuracy: 0.7599 - val_loss: 1.0408 - val_accuracy: 0.6670\n",
      "Accuracy plot is saved to: train_history/cnn7/4_accuracy.png\n",
      "Loss plot is saved to: train_history/cnn7/4_loss.png\n",
      "WARNING:tensorflow:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n",
      "563/563 [==============================] - 6s 10ms/step\n",
      "Accuracy: 66.70%\n",
      "Confusion matrix is saved to: train_history/cnn7/4_confusion_matrix.png\n",
      "Attempt accuracy: 66.70%\n",
      "Attempts accuracy is saved to train_history/cnn7/accuracy.csv\n",
      "Accuracy boxplot is saved to: train_history/cnn7/boxplot.png\n"
     ]
    }
   ],
   "source": [
    "name = 'cnn7'\n",
    "n_epochs = 10\n",
    "optimizer = keras.optimizers.Nadam(learning_rate=0.001)\n",
    "loss = 'sparse_categorical_crossentropy'\n",
    "n_repeat = 5\n",
    "filter = (3, 3)\n",
    "\n",
    "keras.utils.set_random_seed(seed_value)\n",
    "\n",
    "accuracy = []\n",
    "for idx in range(n_repeat):\n",
    "  print(f'Attempt #{idx + 1}')\n",
    "  i = keras.Input(shape=input_shape)\n",
    "  x = keras.layers.Conv2D(32, filter, activation='relu', padding='same')(i)\n",
    "  x = keras.layers.BatchNormalization()(x)\n",
    "  x = keras.layers.Conv2D(32, filter, activation='relu', padding='same')(x)\n",
    "  x = keras.layers.BatchNormalization()(x)\n",
    "  x = keras.layers.MaxPooling2D((2, 2))(x)\n",
    "\n",
    "  x = keras.layers.Conv2D(64, filter, activation='relu', padding='same')(x)\n",
    "  x = keras.layers.BatchNormalization()(x)\n",
    "  x = keras.layers.Conv2D(64, filter, activation='relu', padding='same')(x)\n",
    "  x = keras.layers.BatchNormalization()(x)\n",
    "  x = keras.layers.MaxPooling2D((2, 2))(x)\n",
    "\n",
    "  x = keras.layers.Conv2D(128, filter, activation='relu', padding='same')(x)\n",
    "  x = keras.layers.BatchNormalization()(x)\n",
    "  x = keras.layers.Conv2D(128, filter, activation='relu', padding='same')(x)\n",
    "  x = keras.layers.BatchNormalization()(x)\n",
    "  x = keras.layers.MaxPooling2D((2, 2))(x)\n",
    "\n",
    "  x = keras.layers.Flatten()(x)\n",
    "  x = keras.layers.Dropout(0.2)(x)\n",
    "  x = keras.layers.Dense(1024, activation='relu')(x)\n",
    "  x = keras.layers.Dropout(0.2)(x)\n",
    "  x = keras.layers.Dense(n_classes, activation='softmax')(x)\n",
    "  model = keras.Model(i, x)\n",
    "\n",
    "  model.compile(\n",
    "      optimizer=optimizer,\n",
    "      loss=loss,\n",
    "      metrics=['accuracy']\n",
    "  )\n",
    "\n",
    "  history = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=test_ds,\n",
    "    epochs=n_epochs\n",
    "  )\n",
    "  model.save(f'train_history/{name}/{idx}.keras')\n",
    "  history_df = pd.DataFrame(history.history) \n",
    "  hist_csv_file = 'train_history/' + name + '/' + str(idx) + '_history.csv'\n",
    "  with open(hist_csv_file, mode='w') as f:\n",
    "      history_df.to_csv(f)\n",
    "  plot_accuracy_and_loss(history_df, name, str(idx))\n",
    "  curr_accuracy = plot_confusion_matrix(name, str(idx))\n",
    "  accuracy.append(curr_accuracy)\n",
    "  print(f'Attempt accuracy: {curr_accuracy * 100:.2f}%')\n",
    "\n",
    "accuracy_df = pd.DataFrame(data=accuracy, columns = ['accuracy'])\n",
    "accuracy_csv_file = 'train_history/' + name + '/accuracy.csv'\n",
    "with open(accuracy_csv_file, mode='w') as f:\n",
    "    accuracy_df.to_csv(f)\n",
    "print(f'Attempts accuracy is saved to {accuracy_csv_file}')\n",
    "plot_accuracy_boxplot(accuracy, name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test 8. Optimizer Adam\n",
    "Same architecture\n",
    "\n",
    "Conv2D - (Batch normalization) Conv2D - (Batch normalization) MaxPooling2D - \n",
    "\n",
    "Conv2D - (Batch normalization) Conv2D - (Batch normalization) MaxPooling2D - \n",
    "\n",
    "Conv2D - (Batch normalization) Conv2D - (Batch normalization) MaxPooling2D - \n",
    "\n",
    "(Flatten) Dropout - Dense (1024) - Dropout - Dense (10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempt #1\n",
      "Epoch 1/10\n",
      "4500/4500 [==============================] - 97s 21ms/step - loss: 1.6006 - accuracy: 0.4263 - val_loss: 1.3045 - val_accuracy: 0.5286\n",
      "Epoch 2/10\n",
      "4500/4500 [==============================] - 96s 21ms/step - loss: 1.2667 - accuracy: 0.5458 - val_loss: 1.1906 - val_accuracy: 0.5784\n",
      "Epoch 3/10\n",
      "4500/4500 [==============================] - 98s 22ms/step - loss: 1.1159 - accuracy: 0.6001 - val_loss: 1.1687 - val_accuracy: 0.5959\n",
      "Epoch 4/10\n",
      "4500/4500 [==============================] - 99s 22ms/step - loss: 1.0001 - accuracy: 0.6398 - val_loss: 1.0046 - val_accuracy: 0.6469\n",
      "Epoch 5/10\n",
      "4500/4500 [==============================] - 100s 22ms/step - loss: 0.9028 - accuracy: 0.6752 - val_loss: 0.9748 - val_accuracy: 0.6621\n",
      "Epoch 6/10\n",
      "4500/4500 [==============================] - 100s 22ms/step - loss: 0.8164 - accuracy: 0.7058 - val_loss: 0.9646 - val_accuracy: 0.6670\n",
      "Epoch 7/10\n",
      "4500/4500 [==============================] - 100s 22ms/step - loss: 0.7323 - accuracy: 0.7347 - val_loss: 1.0192 - val_accuracy: 0.6583\n",
      "Epoch 8/10\n",
      "4500/4500 [==============================] - 101s 22ms/step - loss: 0.6565 - accuracy: 0.7634 - val_loss: 0.9980 - val_accuracy: 0.6708\n",
      "Epoch 9/10\n",
      "4500/4500 [==============================] - 101s 22ms/step - loss: 0.5872 - accuracy: 0.7894 - val_loss: 1.0859 - val_accuracy: 0.6677\n",
      "Epoch 10/10\n",
      "4500/4500 [==============================] - 101s 22ms/step - loss: 0.5299 - accuracy: 0.8107 - val_loss: 1.0441 - val_accuracy: 0.6768\n",
      "Accuracy plot is saved to: train_history/cnn8/0_accuracy.png\n",
      "Loss plot is saved to: train_history/cnn8/0_loss.png\n",
      "563/563 [==============================] - 6s 10ms/step\n",
      "Accuracy: 67.68%\n",
      "Confusion matrix is saved to: train_history/cnn8/0_confusion_matrix.png\n",
      "Attempt accuracy: 67.68%\n",
      "Attempt #2\n",
      "Epoch 1/10\n",
      "4500/4500 [==============================] - 100s 22ms/step - loss: 1.8857 - accuracy: 0.3426 - val_loss: 1.5015 - val_accuracy: 0.4439\n",
      "Epoch 2/10\n",
      "4500/4500 [==============================] - 99s 22ms/step - loss: 1.4361 - accuracy: 0.4763 - val_loss: 1.2992 - val_accuracy: 0.5377\n",
      "Epoch 3/10\n",
      "4500/4500 [==============================] - 99s 22ms/step - loss: 1.2490 - accuracy: 0.5494 - val_loss: 1.1895 - val_accuracy: 0.5769\n",
      "Epoch 4/10\n",
      "4500/4500 [==============================] - 99s 22ms/step - loss: 1.1221 - accuracy: 0.5972 - val_loss: 1.0456 - val_accuracy: 0.6291\n",
      "Epoch 5/10\n",
      "4500/4500 [==============================] - 98s 22ms/step - loss: 1.0173 - accuracy: 0.6370 - val_loss: 1.0360 - val_accuracy: 0.6343\n",
      "Epoch 6/10\n",
      "4500/4500 [==============================] - 100s 22ms/step - loss: 0.9333 - accuracy: 0.6676 - val_loss: 0.9711 - val_accuracy: 0.6575\n",
      "Epoch 7/10\n",
      "4500/4500 [==============================] - 99s 22ms/step - loss: 0.8593 - accuracy: 0.6926 - val_loss: 0.9405 - val_accuracy: 0.6708\n",
      "Epoch 8/10\n",
      "4500/4500 [==============================] - 98s 22ms/step - loss: 0.7840 - accuracy: 0.7196 - val_loss: 0.9288 - val_accuracy: 0.6753\n",
      "Epoch 9/10\n",
      "4500/4500 [==============================] - 98s 22ms/step - loss: 0.7150 - accuracy: 0.7452 - val_loss: 0.9709 - val_accuracy: 0.6805\n",
      "Epoch 10/10\n",
      "4500/4500 [==============================] - 99s 22ms/step - loss: 0.6528 - accuracy: 0.7650 - val_loss: 1.0222 - val_accuracy: 0.6722\n",
      "Accuracy plot is saved to: train_history/cnn8/1_accuracy.png\n",
      "Loss plot is saved to: train_history/cnn8/1_loss.png\n",
      "WARNING:tensorflow:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n",
      "563/563 [==============================] - 6s 10ms/step\n",
      "Accuracy: 67.22%\n",
      "Confusion matrix is saved to: train_history/cnn8/1_confusion_matrix.png\n",
      "Attempt accuracy: 67.22%\n",
      "Attempt #3\n",
      "Epoch 1/10\n",
      "4500/4500 [==============================] - 100s 22ms/step - loss: 1.8076 - accuracy: 0.3497 - val_loss: 1.6153 - val_accuracy: 0.4225\n",
      "Epoch 2/10\n",
      "4500/4500 [==============================] - 101s 22ms/step - loss: 1.4027 - accuracy: 0.4889 - val_loss: 1.1971 - val_accuracy: 0.5636\n",
      "Epoch 3/10\n",
      "4500/4500 [==============================] - 123s 27ms/step - loss: 1.2276 - accuracy: 0.5569 - val_loss: 1.0869 - val_accuracy: 0.6108\n",
      "Epoch 4/10\n",
      "4500/4500 [==============================] - 105s 23ms/step - loss: 1.1054 - accuracy: 0.6032 - val_loss: 1.0822 - val_accuracy: 0.6169\n",
      "Epoch 5/10\n",
      "4500/4500 [==============================] - 100s 22ms/step - loss: 1.0010 - accuracy: 0.6403 - val_loss: 1.0460 - val_accuracy: 0.6368\n",
      "Epoch 6/10\n",
      "4500/4500 [==============================] - 100s 22ms/step - loss: 0.9199 - accuracy: 0.6711 - val_loss: 0.9579 - val_accuracy: 0.6615\n",
      "Epoch 7/10\n",
      "4500/4500 [==============================] - 100s 22ms/step - loss: 0.8479 - accuracy: 0.6951 - val_loss: 0.9530 - val_accuracy: 0.6701\n",
      "Epoch 8/10\n",
      "4500/4500 [==============================] - 100s 22ms/step - loss: 0.7769 - accuracy: 0.7202 - val_loss: 0.9678 - val_accuracy: 0.6756\n",
      "Epoch 9/10\n",
      "4500/4500 [==============================] - 101s 22ms/step - loss: 0.7072 - accuracy: 0.7456 - val_loss: 1.0422 - val_accuracy: 0.6601\n",
      "Epoch 10/10\n",
      "4500/4500 [==============================] - 100s 22ms/step - loss: 0.6443 - accuracy: 0.7677 - val_loss: 1.0537 - val_accuracy: 0.6793\n",
      "Accuracy plot is saved to: train_history/cnn8/2_accuracy.png\n",
      "Loss plot is saved to: train_history/cnn8/2_loss.png\n",
      "WARNING:tensorflow:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n",
      "563/563 [==============================] - 6s 10ms/step\n",
      "Accuracy: 67.93%\n",
      "Confusion matrix is saved to: train_history/cnn8/2_confusion_matrix.png\n",
      "Attempt accuracy: 67.93%\n",
      "Attempt #4\n",
      "Epoch 1/10\n",
      "4500/4500 [==============================] - 99s 22ms/step - loss: 1.8476 - accuracy: 0.3560 - val_loss: 1.5175 - val_accuracy: 0.4490\n",
      "Epoch 2/10\n",
      "4500/4500 [==============================] - 98s 22ms/step - loss: 1.3856 - accuracy: 0.4941 - val_loss: 1.2501 - val_accuracy: 0.5442\n",
      "Epoch 3/10\n",
      "4500/4500 [==============================] - 99s 22ms/step - loss: 1.2133 - accuracy: 0.5622 - val_loss: 1.0968 - val_accuracy: 0.6030\n",
      "Epoch 4/10\n",
      "4500/4500 [==============================] - 99s 22ms/step - loss: 1.0919 - accuracy: 0.6062 - val_loss: 1.0435 - val_accuracy: 0.6239\n",
      "Epoch 5/10\n",
      "4500/4500 [==============================] - 99s 22ms/step - loss: 0.9986 - accuracy: 0.6420 - val_loss: 0.9590 - val_accuracy: 0.6602\n",
      "Epoch 6/10\n",
      "4500/4500 [==============================] - 98s 22ms/step - loss: 0.9148 - accuracy: 0.6728 - val_loss: 1.0391 - val_accuracy: 0.6369\n",
      "Epoch 7/10\n",
      "4500/4500 [==============================] - 99s 22ms/step - loss: 0.8368 - accuracy: 0.7007 - val_loss: 1.0201 - val_accuracy: 0.6489\n",
      "Epoch 8/10\n",
      "4500/4500 [==============================] - 99s 22ms/step - loss: 0.7645 - accuracy: 0.7259 - val_loss: 1.0197 - val_accuracy: 0.6541\n",
      "Epoch 9/10\n",
      "4500/4500 [==============================] - 99s 22ms/step - loss: 0.6928 - accuracy: 0.7515 - val_loss: 1.0118 - val_accuracy: 0.6709\n",
      "Epoch 10/10\n",
      "4500/4500 [==============================] - 99s 22ms/step - loss: 0.6322 - accuracy: 0.7700 - val_loss: 1.0211 - val_accuracy: 0.6707\n",
      "Accuracy plot is saved to: train_history/cnn8/3_accuracy.png\n",
      "Loss plot is saved to: train_history/cnn8/3_loss.png\n",
      "WARNING:tensorflow:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n",
      "563/563 [==============================] - 6s 10ms/step\n",
      "Accuracy: 67.07%\n",
      "Confusion matrix is saved to: train_history/cnn8/3_confusion_matrix.png\n",
      "Attempt accuracy: 67.07%\n",
      "Attempt #5\n",
      "Epoch 1/10\n",
      "4500/4500 [==============================] - 99s 22ms/step - loss: 1.8815 - accuracy: 0.3348 - val_loss: 1.5005 - val_accuracy: 0.4423\n",
      "Epoch 2/10\n",
      "4500/4500 [==============================] - 99s 22ms/step - loss: 1.4244 - accuracy: 0.4740 - val_loss: 1.2878 - val_accuracy: 0.5297\n",
      "Epoch 3/10\n",
      "4500/4500 [==============================] - 98s 22ms/step - loss: 1.2620 - accuracy: 0.5413 - val_loss: 1.1490 - val_accuracy: 0.5873\n",
      "Epoch 4/10\n",
      "4500/4500 [==============================] - 99s 22ms/step - loss: 1.1510 - accuracy: 0.5847 - val_loss: 1.0919 - val_accuracy: 0.6036\n",
      "Epoch 5/10\n",
      "4500/4500 [==============================] - 100s 22ms/step - loss: 1.0620 - accuracy: 0.6180 - val_loss: 1.0424 - val_accuracy: 0.6299\n",
      "Epoch 6/10\n",
      "4500/4500 [==============================] - 101s 22ms/step - loss: 0.9781 - accuracy: 0.6475 - val_loss: 1.0522 - val_accuracy: 0.6285\n",
      "Epoch 7/10\n",
      "4500/4500 [==============================] - 100s 22ms/step - loss: 0.9038 - accuracy: 0.6751 - val_loss: 0.9952 - val_accuracy: 0.6516\n",
      "Epoch 8/10\n",
      "4500/4500 [==============================] - 100s 22ms/step - loss: 0.8396 - accuracy: 0.6972 - val_loss: 0.9749 - val_accuracy: 0.6617\n",
      "Epoch 9/10\n",
      "4500/4500 [==============================] - 100s 22ms/step - loss: 0.7749 - accuracy: 0.7199 - val_loss: 0.9769 - val_accuracy: 0.6667\n",
      "Epoch 10/10\n",
      "4500/4500 [==============================] - 100s 22ms/step - loss: 0.7184 - accuracy: 0.7406 - val_loss: 1.0190 - val_accuracy: 0.6627\n",
      "Accuracy plot is saved to: train_history/cnn8/4_accuracy.png\n",
      "Loss plot is saved to: train_history/cnn8/4_loss.png\n",
      "WARNING:tensorflow:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n",
      "563/563 [==============================] - 6s 10ms/step\n",
      "Accuracy: 66.27%\n",
      "Confusion matrix is saved to: train_history/cnn8/4_confusion_matrix.png\n",
      "Attempt accuracy: 66.27%\n",
      "Attempts accuracy is saved to train_history/cnn8/accuracy.csv\n",
      "Accuracy boxplot is saved to: train_history/cnn8/boxplot.png\n"
     ]
    }
   ],
   "source": [
    "name = 'cnn8'\n",
    "n_epochs = 10\n",
    "optimizer = keras.optimizers.Adam(learning_rate=0.001)\n",
    "loss = 'sparse_categorical_crossentropy'\n",
    "n_repeat = 5\n",
    "filter = (3, 3)\n",
    "\n",
    "keras.utils.set_random_seed(seed_value)\n",
    "\n",
    "accuracy = []\n",
    "for idx in range(n_repeat):\n",
    "  print(f'Attempt #{idx + 1}')\n",
    "  i = keras.Input(shape=input_shape)\n",
    "  x = keras.layers.Conv2D(32, filter, activation='relu', padding='same')(i)\n",
    "  x = keras.layers.BatchNormalization()(x)\n",
    "  x = keras.layers.Conv2D(32, filter, activation='relu', padding='same')(x)\n",
    "  x = keras.layers.BatchNormalization()(x)\n",
    "  x = keras.layers.MaxPooling2D((2, 2))(x)\n",
    "\n",
    "  x = keras.layers.Conv2D(64, filter, activation='relu', padding='same')(x)\n",
    "  x = keras.layers.BatchNormalization()(x)\n",
    "  x = keras.layers.Conv2D(64, filter, activation='relu', padding='same')(x)\n",
    "  x = keras.layers.BatchNormalization()(x)\n",
    "  x = keras.layers.MaxPooling2D((2, 2))(x)\n",
    "\n",
    "  x = keras.layers.Conv2D(128, filter, activation='relu', padding='same')(x)\n",
    "  x = keras.layers.BatchNormalization()(x)\n",
    "  x = keras.layers.Conv2D(128, filter, activation='relu', padding='same')(x)\n",
    "  x = keras.layers.BatchNormalization()(x)\n",
    "  x = keras.layers.MaxPooling2D((2, 2))(x)\n",
    "\n",
    "  x = keras.layers.Flatten()(x)\n",
    "  x = keras.layers.Dropout(0.2)(x)\n",
    "  x = keras.layers.Dense(1024, activation='relu')(x)\n",
    "  x = keras.layers.Dropout(0.2)(x)\n",
    "  x = keras.layers.Dense(n_classes, activation='softmax')(x)\n",
    "  model = keras.Model(i, x)\n",
    "\n",
    "  model.compile(\n",
    "      optimizer=optimizer,\n",
    "      loss=loss,\n",
    "      metrics=['accuracy']\n",
    "  )\n",
    "\n",
    "  history = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=test_ds,\n",
    "    epochs=n_epochs\n",
    "  )\n",
    "  model.save(f'train_history/{name}/{idx}.keras')\n",
    "  history_df = pd.DataFrame(history.history) \n",
    "  hist_csv_file = 'train_history/' + name + '/' + str(idx) + '_history.csv'\n",
    "  with open(hist_csv_file, mode='w') as f:\n",
    "      history_df.to_csv(f)\n",
    "  plot_accuracy_and_loss(history_df, name, str(idx))\n",
    "  curr_accuracy = plot_confusion_matrix(name, str(idx))\n",
    "  accuracy.append(curr_accuracy)\n",
    "  print(f'Attempt accuracy: {curr_accuracy * 100:.2f}%')\n",
    "\n",
    "accuracy_df = pd.DataFrame(data=accuracy, columns = ['accuracy'])\n",
    "accuracy_csv_file = 'train_history/' + name + '/accuracy.csv'\n",
    "with open(accuracy_csv_file, mode='w') as f:\n",
    "    accuracy_df.to_csv(f)\n",
    "print(f'Attempts accuracy is saved to {accuracy_csv_file}')\n",
    "plot_accuracy_boxplot(accuracy, name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test 9. Optimizer adamax; learning rate tuning\n",
    "\n",
    "Same architecture. Learning rates: 0.0005, 0.001, 0.005, 0.01, 0.05, 0.1\n",
    "\n",
    "Conv2D - (Batch normalization) Conv2D - (Batch normalization) MaxPooling2D - \n",
    "\n",
    "Conv2D - (Batch normalization) Conv2D - (Batch normalization) MaxPooling2D - \n",
    "\n",
    "Conv2D - (Batch normalization) Conv2D - (Batch normalization) MaxPooling2D - \n",
    "\n",
    "(Flatten) Dropout - Dense (1024) - Dropout - Dense (10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempt #1\n",
      "Learning rate: 0.0005\n",
      "Epoch 1/10\n",
      "4500/4500 [==============================] - 96s 21ms/step - loss: 1.6328 - accuracy: 0.4146 - val_loss: 1.2856 - val_accuracy: 0.5304\n",
      "Epoch 2/10\n",
      "4500/4500 [==============================] - 97s 22ms/step - loss: 1.2633 - accuracy: 0.5387 - val_loss: 1.1285 - val_accuracy: 0.5940\n",
      "Epoch 3/10\n",
      "4500/4500 [==============================] - 100s 22ms/step - loss: 1.0970 - accuracy: 0.6035 - val_loss: 1.0582 - val_accuracy: 0.6219\n",
      "Epoch 4/10\n",
      "4500/4500 [==============================] - 101s 22ms/step - loss: 0.9771 - accuracy: 0.6491 - val_loss: 1.0171 - val_accuracy: 0.6399\n",
      "Epoch 5/10\n",
      "4500/4500 [==============================] - 101s 22ms/step - loss: 0.8767 - accuracy: 0.6825 - val_loss: 0.9915 - val_accuracy: 0.6474\n",
      "Epoch 6/10\n",
      "4500/4500 [==============================] - 101s 23ms/step - loss: 0.7847 - accuracy: 0.7174 - val_loss: 0.9644 - val_accuracy: 0.6658\n",
      "Epoch 7/10\n",
      "4500/4500 [==============================] - 102s 23ms/step - loss: 0.6947 - accuracy: 0.7494 - val_loss: 0.9767 - val_accuracy: 0.6659\n",
      "Epoch 8/10\n",
      "4500/4500 [==============================] - 101s 22ms/step - loss: 0.6096 - accuracy: 0.7804 - val_loss: 0.9858 - val_accuracy: 0.6679\n",
      "Epoch 9/10\n",
      "4500/4500 [==============================] - 102s 23ms/step - loss: 0.5315 - accuracy: 0.8097 - val_loss: 1.0094 - val_accuracy: 0.6698\n",
      "Epoch 10/10\n",
      "4500/4500 [==============================] - 101s 23ms/step - loss: 0.4630 - accuracy: 0.8337 - val_loss: 1.0351 - val_accuracy: 0.6708\n",
      "Accuracy plot is saved to: train_history/cnn8/0_accuracy.png\n",
      "Loss plot is saved to: train_history/cnn8/0_loss.png\n",
      "563/563 [==============================] - 6s 10ms/step\n",
      "Accuracy: 67.08%\n",
      "Confusion matrix is saved to: train_history/cnn8/0_confusion_matrix.png\n",
      "Attempt accuracy: 67.08%\n",
      "Attempt #2\n",
      "Learning rate: 0.001\n",
      "Epoch 1/10\n",
      "4500/4500 [==============================] - 103s 23ms/step - loss: 1.5509 - accuracy: 0.4395 - val_loss: 1.3088 - val_accuracy: 0.5312\n",
      "Epoch 2/10\n",
      "4500/4500 [==============================] - 103s 23ms/step - loss: 1.1943 - accuracy: 0.5674 - val_loss: 1.1404 - val_accuracy: 0.5996\n",
      "Epoch 3/10\n",
      "4500/4500 [==============================] - 103s 23ms/step - loss: 1.0293 - accuracy: 0.6273 - val_loss: 1.0620 - val_accuracy: 0.6251\n",
      "Epoch 4/10\n",
      "4500/4500 [==============================] - 102s 23ms/step - loss: 0.9025 - accuracy: 0.6749 - val_loss: 1.0225 - val_accuracy: 0.6421\n",
      "Epoch 5/10\n",
      "4500/4500 [==============================] - 102s 23ms/step - loss: 0.7943 - accuracy: 0.7124 - val_loss: 1.0137 - val_accuracy: 0.6588\n",
      "Epoch 6/10\n",
      "4500/4500 [==============================] - 102s 23ms/step - loss: 0.6974 - accuracy: 0.7498 - val_loss: 0.9983 - val_accuracy: 0.6728\n",
      "Epoch 7/10\n",
      "4500/4500 [==============================] - 101s 22ms/step - loss: 0.6067 - accuracy: 0.7812 - val_loss: 1.0010 - val_accuracy: 0.6766\n",
      "Epoch 8/10\n",
      "4500/4500 [==============================] - 102s 23ms/step - loss: 0.5194 - accuracy: 0.8130 - val_loss: 1.0161 - val_accuracy: 0.6789\n",
      "Epoch 9/10\n",
      "4500/4500 [==============================] - 104s 23ms/step - loss: 0.4451 - accuracy: 0.8408 - val_loss: 1.0775 - val_accuracy: 0.6778\n",
      "Epoch 10/10\n",
      "4500/4500 [==============================] - 102s 23ms/step - loss: 0.3794 - accuracy: 0.8643 - val_loss: 1.0827 - val_accuracy: 0.6813\n",
      "Accuracy plot is saved to: train_history/cnn8/1_accuracy.png\n",
      "Loss plot is saved to: train_history/cnn8/1_loss.png\n",
      "563/563 [==============================] - 6s 10ms/step\n",
      "Accuracy: 68.13%\n",
      "Confusion matrix is saved to: train_history/cnn8/1_confusion_matrix.png\n",
      "Attempt accuracy: 68.13%\n",
      "Attempt #3\n",
      "Learning rate: 0.005\n",
      "Epoch 1/10\n",
      "4500/4500 [==============================] - 100s 22ms/step - loss: 1.7253 - accuracy: 0.4020 - val_loss: 1.7826 - val_accuracy: 0.4084\n",
      "Epoch 2/10\n",
      "4500/4500 [==============================] - 99s 22ms/step - loss: 1.2608 - accuracy: 0.5436 - val_loss: 1.1056 - val_accuracy: 0.6025\n",
      "Epoch 3/10\n",
      "4500/4500 [==============================] - 99s 22ms/step - loss: 1.0790 - accuracy: 0.6121 - val_loss: 0.9985 - val_accuracy: 0.6435\n",
      "Epoch 4/10\n",
      "4500/4500 [==============================] - 99s 22ms/step - loss: 0.9465 - accuracy: 0.6616 - val_loss: 0.9767 - val_accuracy: 0.6572\n",
      "Epoch 5/10\n",
      "4500/4500 [==============================] - 100s 22ms/step - loss: 0.8340 - accuracy: 0.7034 - val_loss: 0.9578 - val_accuracy: 0.6706\n",
      "Epoch 6/10\n",
      "4500/4500 [==============================] - 100s 22ms/step - loss: 0.7329 - accuracy: 0.7395 - val_loss: 0.9831 - val_accuracy: 0.6763\n",
      "Epoch 7/10\n",
      "4500/4500 [==============================] - 99s 22ms/step - loss: 0.6352 - accuracy: 0.7728 - val_loss: 0.9727 - val_accuracy: 0.6737\n",
      "Epoch 8/10\n",
      "4500/4500 [==============================] - 99s 22ms/step - loss: 0.5545 - accuracy: 0.8032 - val_loss: 1.0946 - val_accuracy: 0.6717\n",
      "Epoch 9/10\n",
      "4500/4500 [==============================] - 100s 22ms/step - loss: 0.4858 - accuracy: 0.8281 - val_loss: 1.2290 - val_accuracy: 0.6687\n",
      "Epoch 10/10\n",
      "4500/4500 [==============================] - 100s 22ms/step - loss: 0.4261 - accuracy: 0.8489 - val_loss: 1.0968 - val_accuracy: 0.6814\n",
      "Accuracy plot is saved to: train_history/cnn8/2_accuracy.png\n",
      "Loss plot is saved to: train_history/cnn8/2_loss.png\n",
      "563/563 [==============================] - 6s 10ms/step\n",
      "Accuracy: 68.14%\n",
      "Confusion matrix is saved to: train_history/cnn8/2_confusion_matrix.png\n",
      "Attempt accuracy: 68.14%\n",
      "Attempt #4\n",
      "Learning rate: 0.01\n",
      "Epoch 1/10\n",
      "4500/4500 [==============================] - 102s 22ms/step - loss: 1.9952 - accuracy: 0.3283 - val_loss: 1.5366 - val_accuracy: 0.4443\n",
      "Epoch 2/10\n",
      "4500/4500 [==============================] - 102s 23ms/step - loss: 1.3618 - accuracy: 0.5035 - val_loss: 1.2295 - val_accuracy: 0.5494\n",
      "Epoch 3/10\n",
      "4500/4500 [==============================] - 101s 23ms/step - loss: 1.2000 - accuracy: 0.5693 - val_loss: 1.6088 - val_accuracy: 0.4537\n",
      "Epoch 4/10\n",
      "4500/4500 [==============================] - 101s 22ms/step - loss: 1.0974 - accuracy: 0.6058 - val_loss: 1.1550 - val_accuracy: 0.5952\n",
      "Epoch 5/10\n",
      "4500/4500 [==============================] - 102s 23ms/step - loss: 1.0183 - accuracy: 0.6354 - val_loss: 1.0451 - val_accuracy: 0.6297\n",
      "Epoch 6/10\n",
      "4500/4500 [==============================] - 101s 22ms/step - loss: 0.9566 - accuracy: 0.6586 - val_loss: 1.0172 - val_accuracy: 0.6402\n",
      "Epoch 7/10\n",
      "4500/4500 [==============================] - 101s 22ms/step - loss: 0.9009 - accuracy: 0.6793 - val_loss: 1.0491 - val_accuracy: 0.6454\n",
      "Epoch 8/10\n",
      "4500/4500 [==============================] - 101s 23ms/step - loss: 0.8511 - accuracy: 0.6968 - val_loss: 1.0109 - val_accuracy: 0.6554\n",
      "Epoch 9/10\n",
      "4500/4500 [==============================] - 101s 22ms/step - loss: 0.7981 - accuracy: 0.7150 - val_loss: 1.0331 - val_accuracy: 0.6515\n",
      "Epoch 10/10\n",
      "4500/4500 [==============================] - 101s 22ms/step - loss: 0.7584 - accuracy: 0.7316 - val_loss: 1.0659 - val_accuracy: 0.6565\n",
      "Accuracy plot is saved to: train_history/cnn8/3_accuracy.png\n",
      "Loss plot is saved to: train_history/cnn8/3_loss.png\n",
      "563/563 [==============================] - 6s 10ms/step\n",
      "Accuracy: 65.65%\n",
      "Confusion matrix is saved to: train_history/cnn8/3_confusion_matrix.png\n",
      "Attempt accuracy: 65.65%\n",
      "Attempt #5\n",
      "Learning rate: 0.05\n",
      "Epoch 1/10\n",
      "4500/4500 [==============================] - 102s 22ms/step - loss: 3.2629 - accuracy: 0.1528 - val_loss: 2.2267 - val_accuracy: 0.1487\n",
      "Epoch 2/10\n",
      "4500/4500 [==============================] - 101s 22ms/step - loss: 1.9639 - accuracy: 0.2338 - val_loss: 1.7879 - val_accuracy: 0.3204\n",
      "Epoch 3/10\n",
      "4500/4500 [==============================] - 101s 22ms/step - loss: 1.7766 - accuracy: 0.3238 - val_loss: 1.6596 - val_accuracy: 0.4086\n",
      "Epoch 4/10\n",
      "4500/4500 [==============================] - 101s 22ms/step - loss: 1.6218 - accuracy: 0.3963 - val_loss: 1.4434 - val_accuracy: 0.4733\n",
      "Epoch 5/10\n",
      "4500/4500 [==============================] - 101s 22ms/step - loss: 1.5396 - accuracy: 0.4353 - val_loss: 1.4682 - val_accuracy: 0.4623\n",
      "Epoch 6/10\n",
      "4500/4500 [==============================] - 100s 22ms/step - loss: 1.4757 - accuracy: 0.4685 - val_loss: 1.5128 - val_accuracy: 0.5429\n",
      "Epoch 7/10\n",
      "4500/4500 [==============================] - 101s 22ms/step - loss: 1.4259 - accuracy: 0.4879 - val_loss: 2.2925 - val_accuracy: 0.5339\n",
      "Epoch 8/10\n",
      "4500/4500 [==============================] - 101s 22ms/step - loss: 1.3863 - accuracy: 0.5040 - val_loss: 1.3832 - val_accuracy: 0.5067\n",
      "Epoch 9/10\n",
      "4500/4500 [==============================] - 101s 22ms/step - loss: 1.3582 - accuracy: 0.5149 - val_loss: 1.3752 - val_accuracy: 0.5465\n",
      "Epoch 10/10\n",
      "4500/4500 [==============================] - 101s 22ms/step - loss: 1.3247 - accuracy: 0.5277 - val_loss: 1.5913 - val_accuracy: 0.5288\n",
      "Accuracy plot is saved to: train_history/cnn8/4_accuracy.png\n",
      "Loss plot is saved to: train_history/cnn8/4_loss.png\n",
      "563/563 [==============================] - 6s 10ms/step\n",
      "Accuracy: 52.88%\n",
      "Confusion matrix is saved to: train_history/cnn8/4_confusion_matrix.png\n",
      "Attempt accuracy: 52.88%\n",
      "Attempt #6\n",
      "Learning rate: 0.1\n",
      "Epoch 1/10\n",
      "4500/4500 [==============================] - 101s 22ms/step - loss: 4.6466 - accuracy: 0.0995 - val_loss: 2.3352 - val_accuracy: 0.1017\n",
      "Epoch 2/10\n",
      "4500/4500 [==============================] - 100s 22ms/step - loss: 2.3089 - accuracy: 0.0991 - val_loss: 2.3103 - val_accuracy: 0.0983\n",
      "Epoch 3/10\n",
      "4500/4500 [==============================] - 100s 22ms/step - loss: 2.3086 - accuracy: 0.0997 - val_loss: 2.3060 - val_accuracy: 0.1004\n",
      "Epoch 4/10\n",
      "4500/4500 [==============================] - 101s 22ms/step - loss: 2.3089 - accuracy: 0.0991 - val_loss: 2.3053 - val_accuracy: 0.0987\n",
      "Epoch 5/10\n",
      "4500/4500 [==============================] - 100s 22ms/step - loss: 2.3087 - accuracy: 0.0984 - val_loss: 2.3051 - val_accuracy: 0.1016\n",
      "Epoch 6/10\n",
      "4500/4500 [==============================] - 100s 22ms/step - loss: 2.3086 - accuracy: 0.0991 - val_loss: 2.3071 - val_accuracy: 0.1016\n",
      "Epoch 7/10\n",
      "4500/4500 [==============================] - 100s 22ms/step - loss: 2.3087 - accuracy: 0.0992 - val_loss: 2.3081 - val_accuracy: 0.0987\n",
      "Epoch 8/10\n",
      "4500/4500 [==============================] - 100s 22ms/step - loss: 2.3088 - accuracy: 0.0989 - val_loss: 2.3068 - val_accuracy: 0.0987\n",
      "Epoch 9/10\n",
      "4500/4500 [==============================] - 100s 22ms/step - loss: 2.3089 - accuracy: 0.0988 - val_loss: 2.3074 - val_accuracy: 0.1017\n",
      "Epoch 10/10\n",
      "4500/4500 [==============================] - 99s 22ms/step - loss: 2.3086 - accuracy: 0.0988 - val_loss: 2.3076 - val_accuracy: 0.1016\n",
      "Accuracy plot is saved to: train_history/cnn8/5_accuracy.png\n",
      "Loss plot is saved to: train_history/cnn8/5_loss.png\n",
      "563/563 [==============================] - 6s 10ms/step\n",
      "Accuracy: 10.16%\n",
      "Confusion matrix is saved to: train_history/cnn8/5_confusion_matrix.png\n",
      "Attempt accuracy: 10.16%\n",
      "Attempts accuracy is saved to train_history/cnn8/accuracy.csv\n",
      "Accuracy boxplot is saved to: train_history/cnn8/boxplot.png\n"
     ]
    }
   ],
   "source": [
    "name = 'cnn9'\n",
    "n_epochs = 10\n",
    "loss = 'sparse_categorical_crossentropy'\n",
    "n_repeat = 5\n",
    "filter = (3, 3)\n",
    "\n",
    "l_rates = [0.0005, 0.001, 0.005, 0.01, 0.05, 0.1]\n",
    "\n",
    "keras.utils.set_random_seed(seed_value)\n",
    "\n",
    "accuracy = []\n",
    "for idx, learning_rate in enumerate(l_rates):\n",
    "  print(f'Attempt #{idx + 1}')\n",
    "  print(f'Learning rate: {learning_rate}')\n",
    "\n",
    "  optimizer = keras.optimizers.Adamax(learning_rate=learning_rate)\n",
    "  i = keras.Input(shape=input_shape)\n",
    "  x = keras.layers.Conv2D(32, filter, activation='relu', padding='same')(i)\n",
    "  x = keras.layers.BatchNormalization()(x)\n",
    "  x = keras.layers.Conv2D(32, filter, activation='relu', padding='same')(x)\n",
    "  x = keras.layers.BatchNormalization()(x)\n",
    "  x = keras.layers.MaxPooling2D((2, 2))(x)\n",
    "\n",
    "  x = keras.layers.Conv2D(64, filter, activation='relu', padding='same')(x)\n",
    "  x = keras.layers.BatchNormalization()(x)\n",
    "  x = keras.layers.Conv2D(64, filter, activation='relu', padding='same')(x)\n",
    "  x = keras.layers.BatchNormalization()(x)\n",
    "  x = keras.layers.MaxPooling2D((2, 2))(x)\n",
    "\n",
    "  x = keras.layers.Conv2D(128, filter, activation='relu', padding='same')(x)\n",
    "  x = keras.layers.BatchNormalization()(x)\n",
    "  x = keras.layers.Conv2D(128, filter, activation='relu', padding='same')(x)\n",
    "  x = keras.layers.BatchNormalization()(x)\n",
    "  x = keras.layers.MaxPooling2D((2, 2))(x)\n",
    "\n",
    "  x = keras.layers.Flatten()(x)\n",
    "  x = keras.layers.Dropout(0.2)(x)\n",
    "  x = keras.layers.Dense(1024, activation='relu')(x)\n",
    "  x = keras.layers.Dropout(0.2)(x)\n",
    "  x = keras.layers.Dense(n_classes, activation='softmax')(x)\n",
    "  model = keras.Model(i, x)\n",
    "\n",
    "  model.compile(\n",
    "      optimizer=optimizer,\n",
    "      loss=loss,\n",
    "      metrics=['accuracy']\n",
    "  )\n",
    "\n",
    "  history = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=test_ds,\n",
    "    epochs=n_epochs\n",
    "  )\n",
    "  model.save(f'train_history/{name}/{idx}.keras')\n",
    "  history_df = pd.DataFrame(history.history) \n",
    "  hist_csv_file = 'train_history/' + name + '/' + str(idx) + '_history.csv'\n",
    "  with open(hist_csv_file, mode='w') as f:\n",
    "      history_df.to_csv(f)\n",
    "  plot_accuracy_and_loss(history_df, name, str(idx))\n",
    "  curr_accuracy = plot_confusion_matrix(name, str(idx))\n",
    "  accuracy.append(curr_accuracy)\n",
    "  print(f'Attempt accuracy: {curr_accuracy * 100:.2f}%')\n",
    "\n",
    "accuracy_df = pd.DataFrame(data=accuracy, columns = ['accuracy'])\n",
    "accuracy_csv_file = 'train_history/' + name + '/accuracy.csv'\n",
    "with open(accuracy_csv_file, mode='w') as f:\n",
    "    accuracy_df.to_csv(f)\n",
    "print(f'Attempts accuracy is saved to {accuracy_csv_file}')\n",
    "plot_accuracy_boxplot(accuracy, name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Augmentation\n",
    "5 different augmentations are applied to train dataset: rotation, flip, translation, brightness and contrast."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x1400 with 18 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "flip = tf.keras.layers.RandomFlip(\"horizontal\", seed=seed_value)\n",
    "rotate = tf.keras.layers.RandomRotation(0.2,seed=seed_value)\n",
    "translation = tf.keras.layers.RandomTranslation(height_factor=0.2, width_factor=0.2, seed=seed_value)\n",
    " \n",
    "brightness = tf.keras.layers.RandomBrightness([-0.5,0.5], seed=seed_value)\n",
    "contrast = tf.keras.layers.RandomContrast(0.15, seed=seed_value)\n",
    "\n",
    "def flip_map(image, label):\n",
    "    return flip(image), label\n",
    "\n",
    "def rotate_map(image, label):\n",
    "    return rotate(image), label\n",
    "\n",
    "def translation_map(image, label):\n",
    "    return translation(image), label\n",
    "\n",
    "def brightness_map(image, label):\n",
    "    return brightness(image), label\n",
    "\n",
    "def contrast_map(image, label):\n",
    "    return contrast(image), label\n",
    "\n",
    "def augment(ds, map_func):\n",
    "    augmented = ds.map(map_func)\n",
    "    return augmented.prefetch(tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "fliped = augment(train_ds, flip_map)\n",
    "rotated = augment(train_ds, rotate_map)\n",
    "translation_aug = augment(train_ds, translation_map)\n",
    "brightness_aug = augment(train_ds, brightness_map)\n",
    "contrast_aug = augment(train_ds, contrast_map)\n",
    "\n",
    "train_ds = train_ds.concatenate(fliped)\n",
    "train_ds = train_ds.concatenate(rotated)\n",
    "train_ds = train_ds.concatenate(translation_aug)\n",
    "train_ds = train_ds.concatenate(brightness_aug)\n",
    "train_ds = train_ds.concatenate(contrast_aug) \n",
    " \n",
    "fig, ax = plt.subplots(6, 3, figsize=(6,14))\n",
    "for images, labels in train_ds.take(1):\n",
    "    for i in range(3):\n",
    "        ax[0][i].imshow(images[i].numpy().astype(\"uint8\"))\n",
    "        ax[0][i].set_title(\"original\")\n",
    "        # flip\n",
    "        aug_batch = fliped.take(1)\n",
    "        aug_i, aug_l = next(iter(aug_batch))\n",
    "        ax[1][i].imshow(aug_i[i].numpy().astype(\"uint8\"))\n",
    "        ax[1][i].set_title(\"flip\")\n",
    "        # rotate\n",
    "        aug_batch = rotated.take(1)\n",
    "        aug_i, aug_l = next(iter(aug_batch))\n",
    "        ax[2][i].imshow(aug_i[i].numpy().astype(\"uint8\"))\n",
    "        ax[2][i].set_title(\"rotate\")\n",
    "        # translation\n",
    "        aug_batch = translation_aug.take(1)\n",
    "        aug_i, aug_l = next(iter(aug_batch))\n",
    "        ax[3][i].imshow(aug_i[i].numpy().astype(\"uint8\"))\n",
    "        ax[3][i].set_title(\"translation\")\n",
    "        # brightness\n",
    "        aug_batch = brightness_aug.take(1)\n",
    "        aug_i, aug_l = next(iter(aug_batch))\n",
    "        ax[4][i].imshow(aug_i[i].numpy().astype(\"uint8\"))\n",
    "        ax[4][i].set_title(\"brightness\")\n",
    "        # contrast\n",
    "        aug_batch = contrast_aug.take(1)\n",
    "        aug_i, aug_l = next(iter(aug_batch))\n",
    "        ax[5][i].imshow(aug_i[i].numpy().astype(\"uint8\"))\n",
    "        ax[5][i].set_title(\"contrast\")\n",
    "# plt.savefig('augmentation.png')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test 10: CNN6 with augmentation\n",
    "CNN6 with learning rate 0.005, optimizer 'adamax' and augmentation. (5 times more training data).\n",
    "\n",
    "Conv2D - (Batch normalization) Conv2D - (Batch normalization) MaxPooling2D - \n",
    "\n",
    "Conv2D - (Batch normalization) Conv2D - (Batch normalization) MaxPooling2D - \n",
    "\n",
    "Conv2D - (Batch normalization) Conv2D - (Batch normalization) MaxPooling2D - \n",
    "\n",
    "(Flatten) Dropout - Dense (1024) - Dropout - Dense (10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples: 432000\n",
      "Attempt #1\n",
      "Epoch 1/2\n",
      "  253/27000 [..............................] - ETA: 28:23 - loss: 2.5779 - accuracy: 0.2638"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[51], line 48\u001b[0m\n\u001b[0;32m     40\u001b[0m model \u001b[38;5;241m=\u001b[39m keras\u001b[38;5;241m.\u001b[39mModel(i, x)\n\u001b[0;32m     42\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(\n\u001b[0;32m     43\u001b[0m     optimizer\u001b[38;5;241m=\u001b[39moptimizer,\n\u001b[0;32m     44\u001b[0m     loss\u001b[38;5;241m=\u001b[39mloss,\n\u001b[0;32m     45\u001b[0m     metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m     46\u001b[0m )\n\u001b[1;32m---> 48\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     49\u001b[0m \u001b[43m  \u001b[49m\u001b[43mtrain_ds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     50\u001b[0m \u001b[43m  \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest_ds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     51\u001b[0m \u001b[43m  \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_epochs\u001b[49m\n\u001b[0;32m     52\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     53\u001b[0m model\u001b[38;5;241m.\u001b[39msave(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain_history/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00midx\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.keras\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     54\u001b[0m history_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(history\u001b[38;5;241m.\u001b[39mhistory) \n",
      "File \u001b[1;32mc:\\ProgramFiles\\Anaconda3\\envs\\tensorflow\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\ProgramFiles\\Anaconda3\\envs\\tensorflow\\Lib\\site-packages\\keras\\src\\engine\\training.py:1807\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1799\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[0;32m   1800\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1801\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1804\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m   1805\u001b[0m ):\n\u001b[0;32m   1806\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1807\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1808\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[0;32m   1809\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[1;32mc:\\ProgramFiles\\Anaconda3\\envs\\tensorflow\\Lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\ProgramFiles\\Anaconda3\\envs\\tensorflow\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:832\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    829\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    831\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 832\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    834\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    835\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32mc:\\ProgramFiles\\Anaconda3\\envs\\tensorflow\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:868\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    865\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    866\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    867\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 868\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    869\u001b[0m \u001b[43m      \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_no_variable_creation_config\u001b[49m\n\u001b[0;32m    870\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    871\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_config \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    872\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    873\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[0;32m    874\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[1;32mc:\\ProgramFiles\\Anaconda3\\envs\\tensorflow\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[1;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[0;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[1;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[0;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[0;32m    141\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\ProgramFiles\\Anaconda3\\envs\\tensorflow\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\concrete_function.py:1323\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[0;32m   1319\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1320\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1321\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1322\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1323\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1324\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1325\u001b[0m     args,\n\u001b[0;32m   1326\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1327\u001b[0m     executing_eagerly)\n\u001b[0;32m   1328\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32mc:\\ProgramFiles\\Anaconda3\\envs\\tensorflow\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[1;34m(self, args)\u001b[0m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[1;32mc:\\ProgramFiles\\Anaconda3\\envs\\tensorflow\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[0;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[1;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[0;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[0;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[0;32m    261\u001b[0m     )\n",
      "File \u001b[1;32mc:\\ProgramFiles\\Anaconda3\\envs\\tensorflow\\Lib\\site-packages\\tensorflow\\python\\eager\\context.py:1486\u001b[0m, in \u001b[0;36mContext.call_function\u001b[1;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[0;32m   1484\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[0;32m   1485\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1486\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1487\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1488\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1489\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1490\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1491\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1492\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1493\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1494\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m   1495\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1496\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1500\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[0;32m   1501\u001b[0m   )\n",
      "File \u001b[1;32mc:\\ProgramFiles\\Anaconda3\\envs\\tensorflow\\Lib\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "name = 'cnn10'\n",
    "n_epochs = 2\n",
    "optimizer = 'adamax'\n",
    "loss = 'sparse_categorical_crossentropy'\n",
    "n_repeat = 2\n",
    "filter = (3, 3)\n",
    "\n",
    "keras.utils.set_random_seed(seed_value)\n",
    "\n",
    "num_samples = train_ds.cardinality().numpy()\n",
    "print(f'Number of samples: {num_samples*16}')\n",
    "\n",
    "accuracy = []\n",
    "for idx in range(n_repeat):\n",
    "  print(f'Attempt #{idx + 1}')\n",
    "  i = keras.Input(shape=input_shape)\n",
    "  x = keras.layers.Conv2D(32, filter, activation='relu', padding='same')(i)\n",
    "  x = keras.layers.BatchNormalization()(x)\n",
    "  x = keras.layers.Conv2D(32, filter, activation='relu', padding='same')(x)\n",
    "  x = keras.layers.BatchNormalization()(x)\n",
    "  x = keras.layers.MaxPooling2D((2, 2))(x)\n",
    "\n",
    "  x = keras.layers.Conv2D(64, filter, activation='relu', padding='same')(x)\n",
    "  x = keras.layers.BatchNormalization()(x)\n",
    "  x = keras.layers.Conv2D(64, filter, activation='relu', padding='same')(x)\n",
    "  x = keras.layers.BatchNormalization()(x)\n",
    "  x = keras.layers.MaxPooling2D((2, 2))(x)\n",
    "\n",
    "  x = keras.layers.Conv2D(128, filter, activation='relu', padding='same')(x)\n",
    "  x = keras.layers.BatchNormalization()(x)\n",
    "  x = keras.layers.Conv2D(128, filter, activation='relu', padding='same')(x)\n",
    "  x = keras.layers.BatchNormalization()(x)\n",
    "  x = keras.layers.MaxPooling2D((2, 2))(x)\n",
    "\n",
    "  x = keras.layers.Flatten()(x)\n",
    "  x = keras.layers.Dropout(0.2)(x)\n",
    "  x = keras.layers.Dense(1024, activation='relu')(x)\n",
    "  x = keras.layers.Dropout(0.2)(x)\n",
    "  x = keras.layers.Dense(n_classes, activation='softmax')(x)\n",
    "  model = keras.Model(i, x)\n",
    "\n",
    "  model.compile(\n",
    "      optimizer=optimizer,\n",
    "      loss=loss,\n",
    "      metrics=['accuracy']\n",
    "  )\n",
    "\n",
    "  history = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=test_ds,\n",
    "    epochs=n_epochs\n",
    "  )\n",
    "  model.save(f'train_history/{name}/{idx}.keras')\n",
    "  history_df = pd.DataFrame(history.history) \n",
    "  hist_csv_file = 'train_history/' + name + '/' + str(idx) + '_history.csv'\n",
    "  with open(hist_csv_file, mode='w') as f:\n",
    "      history_df.to_csv(f)\n",
    "  plot_accuracy_and_loss(history_df, name, str(idx))\n",
    "  curr_accuracy = plot_confusion_matrix(name, str(idx))\n",
    "  accuracy.append(curr_accuracy)\n",
    "  print(f'Attempt accuracy: {curr_accuracy * 100:.2f}%')\n",
    "\n",
    "accuracy_df = pd.DataFrame(data=accuracy, columns = ['accuracy'])\n",
    "accuracy_csv_file = 'train_history/' + name + '/accuracy.csv'\n",
    "with open(accuracy_csv_file, mode='w') as f:\n",
    "    accuracy_df.to_csv(f)\n",
    "print(f'Attempts accuracy is saved to {accuracy_csv_file}')\n",
    "plot_accuracy_boxplot(accuracy, name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
